// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-27T22:24:53+05:30

package azure

import (
	"encoding/json"
	"fmt"

	"github.com/plantonhq/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// AzureEventHubNamespace is the top-level API resource for an Azure Event
//
//	Hubs namespace. Azure Event Hubs provides fully managed, real-time data
//	ingestion capable of receiving and processing millions of events per second
//	for telemetry, log aggregation, IoT, and real-time analytics.
type AzureEventHubNamespaceSpecInput struct {
	// The Azure region where the Event Hubs namespace will be created.
	//  Examples: "eastus", "westus2", "westeurope", "southeastasia".
	Region string `json:"region" jsonschema:"required,The Azure region where the Event Hubs namespace will be created. Examples: 'eastus'; 'westus2'; 'westeurope'; 'southeastasia'."`
	// The Azure Resource Group where the Event Hubs namespace will be created.
	//  Can be a literal string or a reference to an AzureResourceGroup output.
	ResourceGroup string `json:"resource_group" jsonschema:"required,The Azure Resource Group where the Event Hubs namespace will be created. Can be a literal string or a reference to an AzureResourceGroup output."`
	// The name of the Event Hubs namespace.
	//  Must be globally unique across Azure. Used as the endpoint:
	//  `{name}.servicebus.windows.net`
	//
	//  Naming rules (Azure API enforced):
	//  - 6 to 50 characters
	//  - Must start with a letter
	//  - Must end with a letter or number
	//  - Can contain letters, numbers, and hyphens
	// ...
	Name string `json:"name" jsonschema:"required,The name of the Event Hubs namespace. Must be globally unique across Azure. Used as the endpoint: '{name}.servicebus.windows.net' Naming rules (Azure API enforced): - 6 to 50 characters - Must start w..."`
	// The SKU tier for the Event Hubs namespace.
	//  Uses Azure's exact API values for provider authenticity.
	//
	//  Valid values:
	//  - "Basic": Single consumer group, 1-day retention. Simple ingestion.
	//  - "Standard" (default): Full-featured with Kafka support, auto-inflate,
	//    up to 20 consumer groups, 7-day reten...
	Sku string `json:"sku,omitempty" jsonschema:"The SKU tier for the Event Hubs namespace. Uses Azure's exact API values for provider authenticity. Valid values: - 'Basic': Single consumer group; 1-day retention. Simple ingestion. - 'Standard' (def..."`
	// Capacity for the namespace.
	//  For Standard SKU: throughput units (TUs). Each TU provides 1 MB/s ingress
	//  and 2 MB/s egress. Default 1, max 40 (with auto-inflate).
	//  For Premium SKU: processing units (PUs) for dedicated compute. Valid
	//  values: 1, 2, 4, 8, 16.
	//
	//  Default: 1
	Capacity int32 `json:"capacity,omitempty" jsonschema:"Capacity for the namespace. For Standard SKU: throughput units (TUs). Each TU provides 1 MB/s ingress and 2 MB/s egress. Default 1; max 40 (with auto-inflate). For Premium SKU: processing units (PUs) ..."`
	// Enable auto-inflate (automatic throughput unit scaling) for Standard SKU.
	//  When enabled, the namespace automatically scales throughput units up to
	//  `maximum_throughput_units` based on traffic demand.
	//
	//  Only applicable for Standard SKU. Premium uses fixed processing units.
	//
	//  Default: false
	AutoInflateEnabled bool `json:"auto_inflate_enabled,omitempty" jsonschema:"Enable auto-inflate (automatic throughput unit scaling) for Standard SKU. When enabled; the namespace automatically scales throughput units up to 'maximum_throughput_units' based on traffic demand. On..."`
	// Maximum throughput units when auto-inflate is enabled.
	//  The namespace scales up to this value automatically.
	//
	//  Range: 0-40. A value of 0 effectively disables auto-inflate.
	//  Only meaningful when `auto_inflate_enabled` is true.
	MaximumThroughputUnits int32 `json:"maximum_throughput_units,omitempty" jsonschema:"Maximum throughput units when auto-inflate is enabled. The namespace scales up to this value automatically. Range: 0-40. A value of 0 effectively disables auto-inflate. Only meaningful when 'auto_infl..."`
	// Enable zone redundancy for the namespace.
	//  When enabled, the namespace metadata and data are replicated across
	//  availability zones within the region for higher availability.
	//
	//  Applicable for Standard and Premium SKUs.
	//
	//  Default: false
	ZoneRedundant bool `json:"zone_redundant,omitempty" jsonschema:"Enable zone redundancy for the namespace. When enabled; the namespace metadata and data are replicated across availability zones within the region for higher availability. Applicable for Standard and ..."`
	// Minimum TLS version for client connections.
	//  Azure enforces this on all AMQP, HTTPS, and Kafka connections.
	//
	//  Default: "1.2" (recommended for all production workloads)
	MinimumTlsVersion string `json:"minimum_tls_version,omitempty" jsonschema:"Minimum TLS version for client connections. Azure enforces this on all AMQP; HTTPS; and Kafka connections. Default: '1.2' (recommended for all production workloads)"`
	// Whether the namespace is accessible over the public internet.
	//  When false, the namespace can only be accessed via AzurePrivateEndpoint
	//  or VNet service endpoints.
	//
	//  Default: true
	PublicNetworkAccessEnabled bool `json:"public_network_access_enabled,omitempty" jsonschema:"Whether the namespace is accessible over the public internet. When false; the namespace can only be accessed via AzurePrivateEndpoint or VNet service endpoints. Default: true"`
	// Event hubs within this namespace.
	//  Each event hub is an independent stream of events with its own partition
	//  layout and consumer groups.
	//
	//  Azure creates a default `$Default` consumer group automatically for each
	//  event hub. Additional consumer groups defined here are created alongside it.
	EventHubs []*AzureEventHubInput `json:"event_hubs,omitempty" jsonschema:"Event hubs within this namespace. Each event hub is an independent stream of events with its own partition layout and consumer groups. Azure creates a default '$Default' consumer group automatically f..."`
}

func (s *AzureEventHubNamespaceSpecInput) validate() error {
	if s.Region == "" {
		return fmt.Errorf("region is required")
	}
	if s.ResourceGroup == "" {
		return fmt.Errorf("resource_group is required")
	}
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	for i, v := range s.EventHubs {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("event_hubs[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AzureEventHubNamespaceSpecInput) applyDefaults() {
	if s.Sku == "" {
		s.Sku = "Standard"
	}
	if s.Capacity == 0 {
		s.Capacity = 1
	}
	if s.MinimumTlsVersion == "" {
		s.MinimumTlsVersion = "1.2"
	}
	// default: PublicNetworkAccessEnabled = true (applied at zero-value)
}

func (s *AzureEventHubNamespaceSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	m["region"] = s.Region
	m["resource_group"] = s.ResourceGroup
	m["name"] = s.Name
	if s.Sku != "" {
		m["sku"] = s.Sku
	}
	if s.Capacity != 0 {
		m["capacity"] = s.Capacity
	}
	if s.AutoInflateEnabled {
		m["auto_inflate_enabled"] = s.AutoInflateEnabled
	}
	if s.MaximumThroughputUnits != 0 {
		m["maximum_throughput_units"] = s.MaximumThroughputUnits
	}
	if s.ZoneRedundant {
		m["zone_redundant"] = s.ZoneRedundant
	}
	if s.MinimumTlsVersion != "" {
		m["minimum_tls_version"] = s.MinimumTlsVersion
	}
	if s.PublicNetworkAccessEnabled {
		m["public_network_access_enabled"] = s.PublicNetworkAccessEnabled
	}
	if len(s.EventHubs) > 0 {
		items := make([]any, len(s.EventHubs))
		for i, v := range s.EventHubs {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["event_hubs"] = items
	}
	return m
}

// AzureEventHub defines an event hub within the Event Hubs namespace.
//
//	An event hub is the core streaming entity. Events are published to an event
//	hub by producers and consumed by consumer groups. Each event hub has a fixed
//	number of partitions that determine the degree of downstream parallelism.
//
//	Key concepts:
//	- **Partitions**: Ordered sequences of events. Each partition is consumed
//	  independently. More partitions = higher throughput parallelism.
//	  Cannot be decreased after creation.
//	- **Message retention**: How long events are retained in the event hub.
//	  Consumers can replay events within the retention window.
//	- **Consumer groups**: Isolated views of the event stream. Each consumer
//	  group maintains its own read position (offset) independently.
//
//	**ForceNew fields**: `name`.
type AzureEventHubInput struct {
	// The event hub name.
	//  Must be unique within the namespace.
	//
	//  Naming rules: 1-256 characters. Must start and end with a letter or
	//  number. Can contain letters, numbers, periods, hyphens, underscores.
	Name string `json:"name" jsonschema:"required,The event hub name. Must be unique within the namespace. Naming rules: 1-256 characters. Must start and end with a letter or number. Can contain letters; numbers; periods; hyphens; underscores."`
	// Number of partitions for the event hub.
	//  Determines the maximum downstream parallelism. Each partition is an
	//  ordered sequence of events consumed independently.
	//
	//  Range: 1-32 (shared namespaces).
	//
	//  **Important**: Partition count cannot be decreased after creation.
	//  Plan for peak throughput needs upf...
	PartitionCount int32 `json:"partition_count" jsonschema:"required,Number of partitions for the event hub. Determines the maximum downstream parallelism. Each partition is an ordered sequence of events consumed independently. Range: 1-32 (shared namespaces). **Import..."`
	// Message retention in days.
	//  Events are retained for this duration and can be replayed by consumers.
	//
	//  Range: 1-7 days (shared namespaces).
	//  Default: 1 day.
	//
	//  Higher retention enables longer replay windows for reprocessing scenarios
	//  but increases storage costs.
	MessageRetention int32 `json:"message_retention,omitempty" jsonschema:"Message retention in days. Events are retained for this duration and can be replayed by consumers. Range: 1-7 days (shared namespaces). Default: 1 day. Higher retention enables longer replay windows f..."`
	// Consumer groups for this event hub.
	//  Each consumer group provides an independent view of the event stream
	//  with its own read position (offset). Multiple consumer applications
	//  can process the same events independently.
	//
	//  Azure creates a `$Default` consumer group automatically. Groups defined
	//  here a...
	ConsumerGroups []*AzureEventHubConsumerGroupInput `json:"consumer_groups,omitempty" jsonschema:"Consumer groups for this event hub. Each consumer group provides an independent view of the event stream with its own read position (offset). Multiple consumer applications can process the same events..."`
}

func (s *AzureEventHubInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	for i, v := range s.ConsumerGroups {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("consumer_groups[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AzureEventHubInput) applyDefaults() {
	if s.MessageRetention == 0 {
		s.MessageRetention = 1
	}
}

func (s *AzureEventHubInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	m["partition_count"] = s.PartitionCount
	if s.MessageRetention != 0 {
		m["message_retention"] = s.MessageRetention
	}
	if len(s.ConsumerGroups) > 0 {
		items := make([]any, len(s.ConsumerGroups))
		for i, v := range s.ConsumerGroups {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["consumer_groups"] = items
	}
	return m
}

// AzureEventHubConsumerGroup defines a consumer group within an event hub.
//
//	A consumer group is a view of the entire event hub. It enables multiple
//	consuming applications to each have a separate view of the event stream,
//	reading independently at their own pace and with their own offsets.
//
//	**ForceNew fields**: `name`.
type AzureEventHubConsumerGroupInput struct {
	// The consumer group name.
	//  Must be unique within the event hub.
	//
	//  Naming rules: 1-50 characters. Must start and end with a letter or
	//  number. Can contain letters, numbers, periods, hyphens, underscores.
	Name string `json:"name" jsonschema:"required,The consumer group name. Must be unique within the event hub. Naming rules: 1-50 characters. Must start and end with a letter or number. Can contain letters; numbers; periods; hyphens; underscores."`
	// User-defined metadata for the consumer group.
	//  Can store application-specific information such as the consumer
	//  application name, purpose, or team ownership.
	//
	//  Maximum: 1024 characters.
	UserMetadata string `json:"user_metadata,omitempty" jsonschema:"User-defined metadata for the consumer group. Can store application-specific information such as the consumer application name; purpose; or team ownership. Maximum: 1024 characters."`
}

func (s *AzureEventHubConsumerGroupInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	return nil
}

func (s *AzureEventHubConsumerGroupInput) applyDefaults() {
}

func (s *AzureEventHubConsumerGroupInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	if s.UserMetadata != "" {
		m["user_metadata"] = s.UserMetadata
	}
	return m
}

// ParseAzureEventHubNamespace validates and normalizes a AzureEventHubNamespace cloud_object.
func ParseAzureEventHubNamespace(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "azure.openmcf.org/v1", "AzureEventHubNamespace"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec AzureEventHubNamespaceSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
