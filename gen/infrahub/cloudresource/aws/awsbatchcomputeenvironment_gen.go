// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-27T22:24:53+05:30

package aws

import (
	"encoding/json"
	"fmt"

	"github.com/plantonhq/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// AwsBatchComputeEnvironment is a deployment component for creating and managing
//
//	AWS Batch compute environments with bundled job queues and an optional
//	fair-share scheduling policy. This component covers MANAGED compute
//	environments with EC2, SPOT, FARGATE, and FARGATE_SPOT resource types.
type AwsBatchComputeEnvironmentSpecInput struct {
	// The AWS region where the Batch compute environment will be created.
	//  Example: "us-west-2", "eu-west-1"
	Region string `json:"region,omitempty" jsonschema:"The AWS region where the Batch compute environment will be created. Example: 'us-west-2'; 'eu-west-1'"`
	// state controls whether the compute environment accepts jobs.
	//  When DISABLED, the compute environment does not accept new jobs but
	//  existing running jobs continue to completion.
	State string `json:"state,omitempty" jsonschema:"state controls whether the compute environment accepts jobs. When DISABLED; the compute environment does not accept new jobs but existing running jobs continue to completion."`
	// service_role is the IAM role ARN that allows AWS Batch to make API calls
	//  to other AWS services on your behalf. If omitted, AWS Batch uses the
	//  AWSServiceRoleForBatch service-linked role (recommended for most use cases).
	ServiceRole string `json:"service_role,omitempty" jsonschema:"service_role is the IAM role ARN that allows AWS Batch to make API calls to other AWS services on your behalf. If omitted; AWS Batch uses the AWSServiceRoleForBatch service-linked role (recommended fo..."`
	// compute_resources defines the infrastructure backing this compute
	//  environment: instance types, vCPU limits, VPC networking, and scaling.
	ComputeResources *AwsBatchComputeResourcesInput `json:"compute_resources" jsonschema:"required,compute_resources defines the infrastructure backing this compute environment: instance types; vCPU limits; VPC networking; and scaling."`
	// update_policy controls the behavior of infrastructure updates when the
	//  compute environment is modified. Relevant for EC2/SPOT types where
	//  running instances may need replacement.
	UpdatePolicy *AwsBatchUpdatePolicyInput `json:"update_policy,omitempty" jsonschema:"update_policy controls the behavior of infrastructure updates when the compute environment is modified. Relevant for EC2/SPOT types where running instances may need replacement."`
	// job_queues defines one or more job queues that route submitted jobs to this
	//  compute environment. At least one queue is required. Each queue has its own
	//  priority, state, and optional time-limit actions.
	JobQueues []*AwsBatchJobQueueInput `json:"job_queues,omitempty" jsonschema:"job_queues defines one or more job queues that route submitted jobs to this compute environment. At least one queue is required. Each queue has its own priority; state; and optional time-limit actions..."`
	// scheduling_policy defines an optional fair-share scheduling policy. When
	//  provided, a scheduling policy resource is created and attached to all
	//  bundled job queues. Fair-share scheduling divides compute capacity across
	//  share identifiers, preventing any single workload from monopolizing the
	//  compute...
	SchedulingPolicy *AwsBatchSchedulingPolicyInput `json:"scheduling_policy,omitempty" jsonschema:"scheduling_policy defines an optional fair-share scheduling policy. When provided; a scheduling policy resource is created and attached to all bundled job queues. Fair-share scheduling divides compute..."`
}

func (s *AwsBatchComputeEnvironmentSpecInput) validate() error {
	if s.ComputeResources == nil {
		return fmt.Errorf("compute_resources is required")
	}
	if s.ComputeResources != nil {
		if err := s.ComputeResources.validate(); err != nil {
			return fmt.Errorf("compute_resources: %w", err)
		}
	}
	if s.UpdatePolicy != nil {
		if err := s.UpdatePolicy.validate(); err != nil {
			return fmt.Errorf("update_policy: %w", err)
		}
	}
	if len(s.JobQueues) < 1 {
		return fmt.Errorf("job_queues requires at least 1 items, got %d", len(s.JobQueues))
	}
	for i, v := range s.JobQueues {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("job_queues[%d]: %w", i, err)
			}
		}
	}
	if s.SchedulingPolicy != nil {
		if err := s.SchedulingPolicy.validate(); err != nil {
			return fmt.Errorf("scheduling_policy: %w", err)
		}
	}
	return nil
}

func (s *AwsBatchComputeEnvironmentSpecInput) applyDefaults() {
	if s.State == "" {
		s.State = "ENABLED"
	}
	if s.ComputeResources != nil {
		s.ComputeResources.applyDefaults()
	}
	if s.UpdatePolicy != nil {
		s.UpdatePolicy.applyDefaults()
	}
	if s.SchedulingPolicy != nil {
		s.SchedulingPolicy.applyDefaults()
	}
}

func (s *AwsBatchComputeEnvironmentSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Region != "" {
		m["region"] = s.Region
	}
	if s.State != "" {
		m["state"] = s.State
	}
	if s.ServiceRole != "" {
		m["service_role"] = s.ServiceRole
	}
	if s.ComputeResources != nil {
		m["compute_resources"] = s.ComputeResources.toMap()
	}
	if s.UpdatePolicy != nil {
		m["update_policy"] = s.UpdatePolicy.toMap()
	}
	if len(s.JobQueues) > 0 {
		items := make([]any, len(s.JobQueues))
		for i, v := range s.JobQueues {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["job_queues"] = items
	}
	if s.SchedulingPolicy != nil {
		m["scheduling_policy"] = s.SchedulingPolicy.toMap()
	}
	return m
}

// AwsBatchComputeResources defines the compute infrastructure for a MANAGED
//
//	compute environment. The resource type determines which fields are applicable:
//
//	  - EC2 / SPOT: Full control over instance types, vCPU scaling, launch
//	    templates, and EC2 configuration. SPOT adds bid_percentage and
//	    spot_iam_fleet_role.
//
//	  - FARGATE / FARGATE_SPOT: Serverless containers — only max_vcpus, subnets,
//	    and security groups are relevant. No instance types or vCPU min/desired.
type AwsBatchComputeResourcesInput struct {
	// type is the compute resource type.
	//    EC2:          On-demand EC2 instances.
	//    SPOT:         EC2 Spot instances (cheaper, can be interrupted).
	//    FARGATE:      Serverless containers (AWS manages infrastructure).
	//    FARGATE_SPOT: Serverless containers at Spot pricing.
	Type string `json:"type,omitempty" jsonschema:"type is the compute resource type. EC2: On-demand EC2 instances. SPOT: EC2 Spot instances (cheaper; can be interrupted). FARGATE: Serverless containers (AWS manages infrastructure). FARGATE_SPOT: Serv..."`
	// max_vcpus is the maximum number of vCPUs that the compute environment
	//  can scale to. For Fargate, this limits total concurrent vCPU capacity.
	MaxVcpus int32 `json:"max_vcpus" jsonschema:"required,max_vcpus is the maximum number of vCPUs that the compute environment can scale to. For Fargate; this limits total concurrent vCPU capacity."`
	// min_vcpus is the minimum number of vCPUs to maintain, even when there are
	//  no running jobs. Only applicable for EC2 and SPOT types. Set to 0 (default)
	//  to scale to zero when idle.
	MinVcpus int32 `json:"min_vcpus,omitempty" jsonschema:"min_vcpus is the minimum number of vCPUs to maintain; even when there are no running jobs. Only applicable for EC2 and SPOT types. Set to 0 (default) to scale to zero when idle."`
	// desired_vcpus is the initial desired number of vCPUs. AWS Batch adjusts
	//  this value between min_vcpus and max_vcpus based on job queue demand.
	//  Only applicable for EC2 and SPOT types.
	DesiredVcpus int32 `json:"desired_vcpus,omitempty" jsonschema:"desired_vcpus is the initial desired number of vCPUs. AWS Batch adjusts this value between min_vcpus and max_vcpus based on job queue demand. Only applicable for EC2 and SPOT types."`
	// subnet_ids are the VPC subnets where compute resources are launched.
	//  Provide subnets in multiple Availability Zones for high availability.
	SubnetIds []string `json:"subnet_ids" jsonschema:"required,subnet_ids are the VPC subnets where compute resources are launched. Provide subnets in multiple Availability Zones for high availability."`
	// security_group_ids are the VPC security groups to associate with the
	//  compute resources. Required for Fargate types; recommended for EC2/SPOT.
	SecurityGroupIds []string `json:"security_group_ids,omitempty" jsonschema:"security_group_ids are the VPC security groups to associate with the compute resources. Required for Fargate types; recommended for EC2/SPOT."`
	// instance_types specifies the EC2 instance types that may be launched.
	//  Only applicable for EC2 and SPOT types. Use "optimal" to let AWS Batch
	//  select instance types matching job requirements.
	//  Examples: ["m5.xlarge", "c5.xlarge"], ["optimal"]
	InstanceTypes []string `json:"instance_types,omitempty" jsonschema:"instance_types specifies the EC2 instance types that may be launched. Only applicable for EC2 and SPOT types. Use 'optimal' to let AWS Batch select instance types matching job requirements. Examples: ..."`
	// allocation_strategy controls how AWS Batch selects instance types.
	//    BEST_FIT_PROGRESSIVE:           Best fit from cheapest to most expensive.
	//    SPOT_CAPACITY_OPTIMIZED:        Lowest chance of Spot interruption.
	//    SPOT_PRICE_CAPACITY_OPTIMIZED:  Balance of price and interruption risk.
	//  Only appl...
	AllocationStrategy string `json:"allocation_strategy,omitempty" jsonschema:"allocation_strategy controls how AWS Batch selects instance types. BEST_FIT_PROGRESSIVE: Best fit from cheapest to most expensive. SPOT_CAPACITY_OPTIMIZED: Lowest chance of Spot interruption. SPOT_PRI..."`
	// instance_role is the ARN of the IAM instance profile for EC2 instances.
	//  Required for EC2 and SPOT types. The instance profile grants the ECS agent
	//  on each instance permission to communicate with AWS Batch and ECS.
	InstanceRole string `json:"instance_role,omitempty" jsonschema:"instance_role is the ARN of the IAM instance profile for EC2 instances. Required for EC2 and SPOT types. The instance profile grants the ECS agent on each instance permission to communicate with AWS B..."`
	// ec2_key_pair is the name of an EC2 key pair for SSH access to instances.
	//  Only applicable for EC2 and SPOT types. Optional — omit if SSH access
	//  is not needed.
	Ec2KeyPair string `json:"ec2_key_pair,omitempty" jsonschema:"ec2_key_pair is the name of an EC2 key pair for SSH access to instances. Only applicable for EC2 and SPOT types. Optional — omit if SSH access is not needed."`
	// bid_percentage is the maximum percentage of the On-Demand price you are
	//  willing to pay for Spot instances. Only applicable for SPOT type.
	//  Range: 0-100. For example, 60 means you will pay up to 60% of On-Demand.
	BidPercentage int32 `json:"bid_percentage,omitempty" jsonschema:"bid_percentage is the maximum percentage of the On-Demand price you are willing to pay for Spot instances. Only applicable for SPOT type. Range: 0-100. For example; 60 means you will pay up to 60% of ..."`
	// spot_iam_fleet_role is the ARN of the IAM role for Amazon EC2 Spot Fleet
	//  to make requests on your behalf. Required for SPOT type.
	SpotIamFleetRole string `json:"spot_iam_fleet_role,omitempty" jsonschema:"spot_iam_fleet_role is the ARN of the IAM role for Amazon EC2 Spot Fleet to make requests on your behalf. Required for SPOT type."`
	// launch_template specifies a custom EC2 launch template for instances.
	//  Only applicable for EC2 and SPOT types. Use this for custom AMIs,
	//  user data scripts, or advanced instance configuration.
	LaunchTemplate *AwsBatchLaunchTemplateInput `json:"launch_template,omitempty" jsonschema:"launch_template specifies a custom EC2 launch template for instances. Only applicable for EC2 and SPOT types. Use this for custom AMIs; user data scripts; or advanced instance configuration."`
	// ec2_configurations customizes the AMI used by compute resources.
	//  Only applicable for EC2 and SPOT types. Maximum 2 entries.
	Ec2Configurations []*AwsBatchEc2ConfigurationInput `json:"ec2_configurations,omitempty" jsonschema:"ec2_configurations customizes the AMI used by compute resources. Only applicable for EC2 and SPOT types. Maximum 2 entries."`
	// resource_tags are tags applied to the underlying compute resources
	//  (EC2 instances, Spot requests) — separate from the compute environment
	//  resource tags managed by OpenMCF.
	ResourceTags map[string]string `json:"resource_tags,omitempty" jsonschema:"resource_tags are tags applied to the underlying compute resources (EC2 instances; Spot requests) — separate from the compute environment resource tags managed by OpenMCF."`
}

func (s *AwsBatchComputeResourcesInput) validate() error {
	if len(s.SubnetIds) == 0 {
		return fmt.Errorf("subnet_ids is required")
	}
	if len(s.SubnetIds) < 1 {
		return fmt.Errorf("subnet_ids requires at least 1 items, got %d", len(s.SubnetIds))
	}
	if s.LaunchTemplate != nil {
		if err := s.LaunchTemplate.validate(); err != nil {
			return fmt.Errorf("launch_template: %w", err)
		}
	}
	for i, v := range s.Ec2Configurations {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("ec2_configurations[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsBatchComputeResourcesInput) applyDefaults() {
	if s.MinVcpus == 0 {
		s.MinVcpus = 0
	}
	if s.LaunchTemplate != nil {
		s.LaunchTemplate.applyDefaults()
	}
}

func (s *AwsBatchComputeResourcesInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Type != "" {
		m["type"] = s.Type
	}
	m["max_vcpus"] = s.MaxVcpus
	if s.MinVcpus != 0 {
		m["min_vcpus"] = s.MinVcpus
	}
	if s.DesiredVcpus != 0 {
		m["desired_vcpus"] = s.DesiredVcpus
	}
	m["subnet_ids"] = s.SubnetIds
	if len(s.SecurityGroupIds) > 0 {
		m["security_group_ids"] = s.SecurityGroupIds
	}
	if len(s.InstanceTypes) > 0 {
		m["instance_types"] = s.InstanceTypes
	}
	if s.AllocationStrategy != "" {
		m["allocation_strategy"] = s.AllocationStrategy
	}
	if s.InstanceRole != "" {
		m["instance_role"] = s.InstanceRole
	}
	if s.Ec2KeyPair != "" {
		m["ec2_key_pair"] = s.Ec2KeyPair
	}
	if s.BidPercentage != 0 {
		m["bid_percentage"] = s.BidPercentage
	}
	if s.SpotIamFleetRole != "" {
		m["spot_iam_fleet_role"] = s.SpotIamFleetRole
	}
	if s.LaunchTemplate != nil {
		m["launch_template"] = s.LaunchTemplate.toMap()
	}
	if len(s.Ec2Configurations) > 0 {
		items := make([]any, len(s.Ec2Configurations))
		for i, v := range s.Ec2Configurations {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["ec2_configurations"] = items
	}
	if len(s.ResourceTags) > 0 {
		m["resource_tags"] = s.ResourceTags
	}
	return m
}

// AwsBatchEc2Configuration customizes the AMI used by compute resources.
type AwsBatchEc2ConfigurationInput struct {
	// image_type specifies the image type to match. Examples: "ECS_AL2",
	//  "ECS_AL2023", "EKS_AL2". Defaults to "ECS_AL2" if omitted.
	ImageType string `json:"image_type,omitempty" jsonschema:"image_type specifies the image type to match. Examples: 'ECS_AL2'; 'ECS_AL2023'; 'EKS_AL2'. Defaults to 'ECS_AL2' if omitted."`
	// image_id_override is the AMI ID to use instead of the default for
	//  the specified image_type.
	ImageIdOverride string `json:"image_id_override,omitempty" jsonschema:"image_id_override is the AMI ID to use instead of the default for the specified image_type."`
}

func (s *AwsBatchEc2ConfigurationInput) validate() error {
	return nil
}

func (s *AwsBatchEc2ConfigurationInput) applyDefaults() {
}

func (s *AwsBatchEc2ConfigurationInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.ImageType != "" {
		m["image_type"] = s.ImageType
	}
	if s.ImageIdOverride != "" {
		m["image_id_override"] = s.ImageIdOverride
	}
	return m
}

// AwsBatchJobQueue defines a job queue that routes submitted jobs to the
//
//	parent compute environment. Jobs are submitted to a queue, and the queue
//	dispatches them to the compute environment based on priority ordering.
type AwsBatchJobQueueInput struct {
	// name is the queue name. Must be 1-128 characters: alphanumeric, hyphen,
	//  or underscore, starting with an alphanumeric character.
	Name string `json:"name" jsonschema:"required,name is the queue name. Must be 1-128 characters: alphanumeric; hyphen; or underscore; starting with an alphanumeric character."`
	// state controls whether the job queue accepts new jobs.
	State string `json:"state,omitempty" jsonschema:"state controls whether the job queue accepts new jobs."`
	// priority determines the order in which jobs are dispatched when multiple
	//  queues share a compute environment. Higher values have higher priority.
	Priority int32 `json:"priority" jsonschema:"required,priority determines the order in which jobs are dispatched when multiple queues share a compute environment. Higher values have higher priority."`
	// job_state_time_limit_actions define automatic actions taken when a job
	//  remains in a particular state beyond a time threshold. Useful for
	//  cancelling jobs stuck in RUNNABLE state.
	JobStateTimeLimitActions []*AwsBatchJobStateTimeLimitActionInput `json:"job_state_time_limit_actions,omitempty" jsonschema:"job_state_time_limit_actions define automatic actions taken when a job remains in a particular state beyond a time threshold. Useful for cancelling jobs stuck in RUNNABLE state."`
}

func (s *AwsBatchJobQueueInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	for i, v := range s.JobStateTimeLimitActions {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("job_state_time_limit_actions[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsBatchJobQueueInput) applyDefaults() {
	if s.State == "" {
		s.State = "ENABLED"
	}
}

func (s *AwsBatchJobQueueInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	if s.State != "" {
		m["state"] = s.State
	}
	m["priority"] = s.Priority
	if len(s.JobStateTimeLimitActions) > 0 {
		items := make([]any, len(s.JobStateTimeLimitActions))
		for i, v := range s.JobStateTimeLimitActions {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["job_state_time_limit_actions"] = items
	}
	return m
}

// AwsBatchJobStateTimeLimitAction defines an automatic action to take when
//
//	a job in a specific state exceeds a time limit.
type AwsBatchJobStateTimeLimitActionInput struct {
	// action is the action to take. Currently only "CANCEL" is supported.
	Action string `json:"action" jsonschema:"required,action is the action to take. Currently only 'CANCEL' is supported."`
	// max_time_seconds is the maximum time (in seconds) a job can remain in
	//  the specified state before the action is triggered. Range: 600-86400
	//  (10 minutes to 24 hours).
	MaxTimeSeconds int32 `json:"max_time_seconds" jsonschema:"required,max_time_seconds is the maximum time (in seconds) a job can remain in the specified state before the action is triggered. Range: 600-86400 (10 minutes to 24 hours)."`
	// reason is the human-readable reason string included when the action is
	//  taken. Appears in the job status and can be used for operational debugging.
	Reason string `json:"reason" jsonschema:"required,reason is the human-readable reason string included when the action is taken. Appears in the job status and can be used for operational debugging."`
	// state is the job state to monitor. For example, "RUNNABLE" to catch jobs
	//  that cannot be scheduled due to resource constraints.
	State string `json:"state" jsonschema:"required,state is the job state to monitor. For example; 'RUNNABLE' to catch jobs that cannot be scheduled due to resource constraints."`
}

func (s *AwsBatchJobStateTimeLimitActionInput) validate() error {
	if s.Action == "" {
		return fmt.Errorf("action is required")
	}
	if s.Reason == "" {
		return fmt.Errorf("reason is required")
	}
	if s.State == "" {
		return fmt.Errorf("state is required")
	}
	return nil
}

func (s *AwsBatchJobStateTimeLimitActionInput) applyDefaults() {
}

func (s *AwsBatchJobStateTimeLimitActionInput) toMap() map[string]any {
	m := make(map[string]any)
	m["action"] = s.Action
	m["max_time_seconds"] = s.MaxTimeSeconds
	m["reason"] = s.Reason
	m["state"] = s.State
	return m
}

// AwsBatchLaunchTemplate references an EC2 launch template by ID or name.
//
//	Exactly one of launch_template_id or launch_template_name must be provided.
type AwsBatchLaunchTemplateInput struct {
	// launch_template_id is the ID of the launch template.
	LaunchTemplateId string `json:"launch_template_id,omitempty" jsonschema:"launch_template_id is the ID of the launch template."`
	// launch_template_name is the name of the launch template.
	LaunchTemplateName string `json:"launch_template_name,omitempty" jsonschema:"launch_template_name is the name of the launch template."`
	// version is the launch template version. If omitted, the default version
	//  of the launch template is used.
	Version string `json:"version,omitempty" jsonschema:"version is the launch template version. If omitted; the default version of the launch template is used."`
}

func (s *AwsBatchLaunchTemplateInput) validate() error {
	return nil
}

func (s *AwsBatchLaunchTemplateInput) applyDefaults() {
}

func (s *AwsBatchLaunchTemplateInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.LaunchTemplateId != "" {
		m["launch_template_id"] = s.LaunchTemplateId
	}
	if s.LaunchTemplateName != "" {
		m["launch_template_name"] = s.LaunchTemplateName
	}
	if s.Version != "" {
		m["version"] = s.Version
	}
	return m
}

// AwsBatchSchedulingPolicy defines a fair-share scheduling policy that
//
//	distributes compute capacity across share identifiers. When attached to a
//	job queue, it prevents any single workload from monopolizing the compute
//	environment.
type AwsBatchSchedulingPolicyInput struct {
	// compute_reservation is the percentage of vCPUs reserved for share
	//  identifiers not yet represented in the queue. Range: 0-99.
	//  Higher values reserve more capacity for new or underrepresented shares.
	ComputeReservation int32 `json:"compute_reservation,omitempty" jsonschema:"compute_reservation is the percentage of vCPUs reserved for share identifiers not yet represented in the queue. Range: 0-99. Higher values reserve more capacity for new or underrepresented shares."`
	// share_decay_seconds is the time period (in seconds) over which usage
	//  history decays, making recent usage weigh more heavily. Range: 0-604800
	//  (0 to 7 days). Set to 0 to weight all historical usage equally.
	ShareDecaySeconds int32 `json:"share_decay_seconds,omitempty" jsonschema:"share_decay_seconds is the time period (in seconds) over which usage history decays; making recent usage weigh more heavily. Range: 0-604800 (0 to 7 days). Set to 0 to weight all historical usage equa..."`
	// share_distributions define the weight factor for each share identifier,
	//  controlling how compute capacity is divided among different workload
	//  categories.
	ShareDistributions []*AwsBatchShareDistributionInput `json:"share_distributions,omitempty" jsonschema:"share_distributions define the weight factor for each share identifier; controlling how compute capacity is divided among different workload categories."`
}

func (s *AwsBatchSchedulingPolicyInput) validate() error {
	for i, v := range s.ShareDistributions {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("share_distributions[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsBatchSchedulingPolicyInput) applyDefaults() {
}

func (s *AwsBatchSchedulingPolicyInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.ComputeReservation != 0 {
		m["compute_reservation"] = s.ComputeReservation
	}
	if s.ShareDecaySeconds != 0 {
		m["share_decay_seconds"] = s.ShareDecaySeconds
	}
	if len(s.ShareDistributions) > 0 {
		items := make([]any, len(s.ShareDistributions))
		for i, v := range s.ShareDistributions {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["share_distributions"] = items
	}
	return m
}

// AwsBatchShareDistribution defines the weight of a share identifier in the
//
//	fair-share scheduling policy.
type AwsBatchShareDistributionInput struct {
	// share_identifier is a unique identifier for this share. Jobs are assigned
	//  to a share via the schedulingPriorityOverride in their job definition.
	//  Use "*" as the last character for a wildcard prefix match.
	ShareIdentifier string `json:"share_identifier" jsonschema:"required,share_identifier is a unique identifier for this share. Jobs are assigned to a share via the schedulingPriorityOverride in their job definition. Use '*' as the last character for a wildcard prefix mat..."`
	// weight_factor controls the relative share of compute capacity. Higher
	//  weights receive proportionally more capacity. Range: 0.0001-999.9999.
	//  Default is 1.0 if not specified.
	WeightFactor float64 `json:"weight_factor,omitempty" jsonschema:"weight_factor controls the relative share of compute capacity. Higher weights receive proportionally more capacity. Range: 0.0001-999.9999. Default is 1.0 if not specified."`
}

func (s *AwsBatchShareDistributionInput) validate() error {
	if s.ShareIdentifier == "" {
		return fmt.Errorf("share_identifier is required")
	}
	return nil
}

func (s *AwsBatchShareDistributionInput) applyDefaults() {
}

func (s *AwsBatchShareDistributionInput) toMap() map[string]any {
	m := make(map[string]any)
	m["share_identifier"] = s.ShareIdentifier
	if s.WeightFactor != 0 {
		m["weight_factor"] = s.WeightFactor
	}
	return m
}

// AwsBatchUpdatePolicy controls how infrastructure updates are applied to
//
//	the compute environment.
type AwsBatchUpdatePolicyInput struct {
	// terminate_jobs_on_update controls whether running jobs are terminated
	//  when the compute environment infrastructure is updated.
	TerminateJobsOnUpdate bool `json:"terminate_jobs_on_update,omitempty" jsonschema:"terminate_jobs_on_update controls whether running jobs are terminated when the compute environment infrastructure is updated."`
	// job_execution_timeout_minutes is the maximum time (in minutes) to wait
	//  for running jobs to complete before the update proceeds. Only meaningful
	//  when terminate_jobs_on_update is true. Range: 1-360.
	JobExecutionTimeoutMinutes int32 `json:"job_execution_timeout_minutes,omitempty" jsonschema:"job_execution_timeout_minutes is the maximum time (in minutes) to wait for running jobs to complete before the update proceeds. Only meaningful when terminate_jobs_on_update is true. Range: 1-360."`
}

func (s *AwsBatchUpdatePolicyInput) validate() error {
	return nil
}

func (s *AwsBatchUpdatePolicyInput) applyDefaults() {
}

func (s *AwsBatchUpdatePolicyInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.TerminateJobsOnUpdate {
		m["terminate_jobs_on_update"] = s.TerminateJobsOnUpdate
	}
	if s.JobExecutionTimeoutMinutes != 0 {
		m["job_execution_timeout_minutes"] = s.JobExecutionTimeoutMinutes
	}
	return m
}

// ParseAwsBatchComputeEnvironment validates and normalizes a AwsBatchComputeEnvironment cloud_object.
func ParseAwsBatchComputeEnvironment(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "aws.openmcf.org/v1", "AwsBatchComputeEnvironment"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec AwsBatchComputeEnvironmentSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
