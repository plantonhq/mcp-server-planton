// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-26T22:50:56+05:30

package azure

import (
	"encoding/json"
	"fmt"

	"github.com/plantoncloud/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// azure-aks-cluster
type AzureAksClusterSpecInput struct {
	// Azure region in which to create the AKS cluster (e.g., "eastus").
	Region string `json:"region" jsonschema:"required,Azure region in which to create the AKS cluster (e.g.; 'eastus')."`
	// The Azure Resource Group where the AKS Cluster will be created.
	//  Can be a literal string or a reference to an AzureResourceGroup output.
	ResourceGroup string `json:"resource_group" jsonschema:"required,The Azure Resource Group where the AKS Cluster will be created. Can be a literal string or a reference to an AzureResourceGroup output."`
	// The Azure resource ID of the Virtual Network subnet to use for cluster nodes.
	//  This should reference the subnet created by an AzureVirtualNetwork resource.
	VnetSubnetId string `json:"vnet_subnet_id" jsonschema:"required,The Azure resource ID of the Virtual Network subnet to use for cluster nodes. This should reference the subnet created by an AzureVirtualNetwork resource."`
	// Kubernetes version for the cluster control plane.
	//  It is recommended to explicitly set a version (e.g., "1.30") for production clusters to prevent unintended upgrades.
	KubernetesVersion string `json:"kubernetes_version,omitempty" jsonschema:"Kubernetes version for the cluster control plane. It is recommended to explicitly set a version (e.g.; '1.30') for production clusters to prevent unintended upgrades."`
	// Control plane SKU tier. STANDARD provides financially-backed 99.95% uptime SLA (with AZs) and is required for production.
	//  FREE tier has no SLA and is only suitable for dev/test environments.
	//  Defaults to STANDARD for production-ready deployments.
	ControlPlaneSku string `json:"control_plane_sku,omitempty" jsonschema:"enum=FREE,Control plane SKU tier. STANDARD provides financially-backed 99.95% uptime SLA (with AZs) and is required for production. FREE tier has no SLA and is only suitable for dev/test environments. Defaults ..."`
	// Networking plugin for the AKS cluster.
	//  AZURE_CNI provides advanced networking with full VNet integration. KUBENET is deprecated and will be retired in March 2028.
	//  Defaults to AZURE_CNI.
	NetworkPlugin string `json:"network_plugin,omitempty" jsonschema:"enum=KUBENET,Networking plugin for the AKS cluster. AZURE_CNI provides advanced networking with full VNet integration. KUBENET is deprecated and will be retired in March 2028. Defaults to AZURE_CNI."`
	// Network plugin mode for Azure CNI. Only applicable when network_plugin is AZURE_CNI.
	//  OVERLAY mode (recommended) uses a private CIDR for pods (10.244.0.0/16) and solves VNet IP exhaustion.
	//  DYNAMIC mode assigns pods real VNet IPs dynamically from a dedicated pod subnet.
	//  Defaults to OVERLAY.
	NetworkPluginMode string `json:"network_plugin_mode,omitempty" jsonschema:"enum=DYNAMIC,Network plugin mode for Azure CNI. Only applicable when network_plugin is AZURE_CNI. OVERLAY mode (recommended) uses a private CIDR for pods (10.244.0.0/16) and solves VNet IP exhaustion. DYNAMIC mode..."`
	// Deploy the cluster as a private cluster (no public API server endpoint).
	//  When true, the API server endpoint will be private and accessible only from within the VNet.
	//  When false (default), a public endpoint is created (use authorized_ip_ranges to restrict access).
	PrivateClusterEnabled bool `json:"private_cluster_enabled,omitempty" jsonschema:"Deploy the cluster as a private cluster (no public API server endpoint). When true; the API server endpoint will be private and accessible only from within the VNet. When false (default); a public end..."`
	// Authorized IP address ranges (CIDR blocks) that are allowed to access the API server.
	//  This is applicable only if the cluster has a public endpoint.
	//  Leave empty to allow all (0.0.0.0/0) or for private clusters.
	AuthorizedIpRanges []string `json:"authorized_ip_ranges,omitempty" jsonschema:"Authorized IP address ranges (CIDR blocks) that are allowed to access the API server. This is applicable only if the cluster has a public endpoint. Leave empty to allow all (0.0.0.0/0) or for private ..."`
	// Disable Azure Active Directory integration for Kubernetes RBAC.
	//  By default, AKS clusters have Azure AD integration enabled (this field is false).
	//  Set to true to disable Azure AD RBAC integration.
	DisableAzureAdRbac bool `json:"disable_azure_ad_rbac,omitempty" jsonschema:"Disable Azure Active Directory integration for Kubernetes RBAC. By default; AKS clusters have Azure AD integration enabled (this field is false). Set to true to disable Azure AD RBAC integration."`
	// System node pool configuration. Required for all clusters.
	//  System node pools run critical system pods (CoreDNS, metrics-server, etc.) and are tainted to prevent application workloads.
	//  For production, deploy across 3 availability zones with autoscaling enabled (min: 3, max: 5).
	SystemNodePool *AzureAksClusterSystemNodePoolInput `json:"system_node_pool" jsonschema:"required,System node pool configuration. Required for all clusters. System node pools run critical system pods (CoreDNS; metrics-server; etc.) and are tainted to prevent application workloads. For production; ..."`
	// User node pools for application workloads.
	//  Optional: if not specified, applications can run on system node pool (not recommended for production).
	//  For production, create dedicated user node pools with appropriate VM sizes and autoscaling configuration.
	UserNodePools []*AzureAksClusterUserNodePoolInput `json:"user_node_pools,omitempty" jsonschema:"User node pools for application workloads. Optional: if not specified; applications can run on system node pool (not recommended for production). For production; create dedicated user node pools with ..."`
	// Add-ons configuration for the AKS cluster.
	//  Enables Azure-managed add-ons like Container Insights, Key Vault CSI driver, Azure Policy, and Workload Identity.
	Addons *AzureAksClusterAddonsConfigInput `json:"addons,omitempty" jsonschema:"Add-ons configuration for the AKS cluster. Enables Azure-managed add-ons like Container Insights; Key Vault CSI driver; Azure Policy; and Workload Identity."`
	// Advanced networking configuration.
	//  Optional: most users should rely on defaults. Use this only if you need custom CIDRs or DNS servers.
	AdvancedNetworking *AzureAksClusterAdvancedNetworkingInput `json:"advanced_networking,omitempty" jsonschema:"Advanced networking configuration. Optional: most users should rely on defaults. Use this only if you need custom CIDRs or DNS servers."`
}

func (s *AzureAksClusterSpecInput) validate() error {
	if s.Region == "" {
		return fmt.Errorf("region is required")
	}
	if s.ResourceGroup == "" {
		return fmt.Errorf("resource_group is required")
	}
	if s.VnetSubnetId == "" {
		return fmt.Errorf("vnet_subnet_id is required")
	}
	switch s.ControlPlaneSku {
	case "", "FREE":
	default:
		return fmt.Errorf("invalid control_plane_sku: %q", s.ControlPlaneSku)
	}
	switch s.NetworkPlugin {
	case "", "KUBENET":
	default:
		return fmt.Errorf("invalid network_plugin: %q", s.NetworkPlugin)
	}
	switch s.NetworkPluginMode {
	case "", "DYNAMIC":
	default:
		return fmt.Errorf("invalid network_plugin_mode: %q", s.NetworkPluginMode)
	}
	if s.SystemNodePool == nil {
		return fmt.Errorf("system_node_pool is required")
	}
	if s.SystemNodePool != nil {
		if err := s.SystemNodePool.validate(); err != nil {
			return fmt.Errorf("system_node_pool: %w", err)
		}
	}
	for i, v := range s.UserNodePools {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("user_node_pools[%d]: %w", i, err)
			}
		}
	}
	if s.Addons != nil {
		if err := s.Addons.validate(); err != nil {
			return fmt.Errorf("addons: %w", err)
		}
	}
	if s.AdvancedNetworking != nil {
		if err := s.AdvancedNetworking.validate(); err != nil {
			return fmt.Errorf("advanced_networking: %w", err)
		}
	}
	return nil
}

func (s *AzureAksClusterSpecInput) applyDefaults() {
	if s.SystemNodePool != nil {
		s.SystemNodePool.applyDefaults()
	}
	if s.Addons != nil {
		s.Addons.applyDefaults()
	}
	if s.AdvancedNetworking != nil {
		s.AdvancedNetworking.applyDefaults()
	}
}

func (s *AzureAksClusterSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	m["region"] = s.Region
	m["resource_group"] = s.ResourceGroup
	m["vnet_subnet_id"] = s.VnetSubnetId
	if s.KubernetesVersion != "" {
		m["kubernetes_version"] = s.KubernetesVersion
	}
	if s.ControlPlaneSku != "" {
		m["control_plane_sku"] = s.ControlPlaneSku
	}
	if s.NetworkPlugin != "" {
		m["network_plugin"] = s.NetworkPlugin
	}
	if s.NetworkPluginMode != "" {
		m["network_plugin_mode"] = s.NetworkPluginMode
	}
	if s.PrivateClusterEnabled {
		m["private_cluster_enabled"] = s.PrivateClusterEnabled
	}
	if len(s.AuthorizedIpRanges) > 0 {
		m["authorized_ip_ranges"] = s.AuthorizedIpRanges
	}
	if s.DisableAzureAdRbac {
		m["disable_azure_ad_rbac"] = s.DisableAzureAdRbac
	}
	if s.SystemNodePool != nil {
		m["system_node_pool"] = s.SystemNodePool.toMap()
	}
	if len(s.UserNodePools) > 0 {
		items := make([]any, len(s.UserNodePools))
		for i, v := range s.UserNodePools {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["user_node_pools"] = items
	}
	if s.Addons != nil {
		m["addons"] = s.Addons.toMap()
	}
	if s.AdvancedNetworking != nil {
		m["advanced_networking"] = s.AdvancedNetworking.toMap()
	}
	return m
}

// Add-ons configuration for the AKS cluster.
type AzureAksClusterAddonsConfigInput struct {
	// Enable Azure Monitor Container Insights.
	//  Streams container logs, metrics, and Kubernetes events to Log Analytics.
	//  Requires log_analytics_workspace_id to be set in spec.
	//  Defaults to true if log_analytics_workspace_id is provided.
	EnableContainerInsights bool `json:"enable_container_insights,omitempty" jsonschema:"Enable Azure Monitor Container Insights. Streams container logs; metrics; and Kubernetes events to Log Analytics. Requires log_analytics_workspace_id to be set in spec. Defaults to true if log_analyti..."`
	// Enable Azure Key Vault CSI driver.
	//  Allows pods to mount secrets from Azure Key Vault as volumes.
	//  Recommended for production. Defaults to true.
	EnableKeyVaultCsiDriver bool `json:"enable_key_vault_csi_driver,omitempty" jsonschema:"Enable Azure Key Vault CSI driver. Allows pods to mount secrets from Azure Key Vault as volumes. Recommended for production. Defaults to true."`
	// Enable Azure Policy add-on.
	//  Enforces policy-based governance on the cluster (pod security standards, resource quotas, etc.).
	//  Recommended for production. Defaults to true.
	EnableAzurePolicy bool `json:"enable_azure_policy,omitempty" jsonschema:"Enable Azure Policy add-on. Enforces policy-based governance on the cluster (pod security standards; resource quotas; etc.). Recommended for production. Defaults to true."`
	// Enable Azure AD Workload Identity.
	//  Allows pods to authenticate to Azure services using Kubernetes service accounts (secret-less authentication).
	//  Recommended for production. Defaults to true.
	EnableWorkloadIdentity bool `json:"enable_workload_identity,omitempty" jsonschema:"Enable Azure AD Workload Identity. Allows pods to authenticate to Azure services using Kubernetes service accounts (secret-less authentication). Recommended for production. Defaults to true."`
	// The Azure resource ID of a Log Analytics Workspace for Container Insights.
	//  Required if enable_container_insights is true.
	LogAnalyticsWorkspaceId string `json:"log_analytics_workspace_id,omitempty" jsonschema:"The Azure resource ID of a Log Analytics Workspace for Container Insights. Required if enable_container_insights is true."`
}

func (s *AzureAksClusterAddonsConfigInput) validate() error {
	return nil
}

func (s *AzureAksClusterAddonsConfigInput) applyDefaults() {
}

func (s *AzureAksClusterAddonsConfigInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.EnableContainerInsights {
		m["enable_container_insights"] = s.EnableContainerInsights
	}
	if s.EnableKeyVaultCsiDriver {
		m["enable_key_vault_csi_driver"] = s.EnableKeyVaultCsiDriver
	}
	if s.EnableAzurePolicy {
		m["enable_azure_policy"] = s.EnableAzurePolicy
	}
	if s.EnableWorkloadIdentity {
		m["enable_workload_identity"] = s.EnableWorkloadIdentity
	}
	if s.LogAnalyticsWorkspaceId != "" {
		m["log_analytics_workspace_id"] = s.LogAnalyticsWorkspaceId
	}
	return m
}

// Advanced networking configuration.
//
//	Optional: most users should rely on defaults.
type AzureAksClusterAdvancedNetworkingInput struct {
	// Pod CIDR for Overlay mode (e.g., "10.244.0.0/16").
	//  Only applicable when network_plugin_mode is OVERLAY.
	//  Leave empty to use default (10.244.0.0/16).
	PodCidr string `json:"pod_cidr,omitempty" jsonschema:"Pod CIDR for Overlay mode (e.g.; '10.244.0.0/16'). Only applicable when network_plugin_mode is OVERLAY. Leave empty to use default (10.244.0.0/16)."`
	// Service CIDR for Kubernetes services (e.g., "10.0.0.0/16").
	//  Must not overlap with VNet, pod CIDR, or other networks.
	//  Leave empty to use default (10.0.0.0/16).
	ServiceCidr string `json:"service_cidr,omitempty" jsonschema:"Service CIDR for Kubernetes services (e.g.; '10.0.0.0/16'). Must not overlap with VNet; pod CIDR; or other networks. Leave empty to use default (10.0.0.0/16)."`
	// DNS service IP address (must be within service_cidr range).
	//  Leave empty to use default (10.0.0.10).
	DnsServiceIp string `json:"dns_service_ip,omitempty" jsonschema:"DNS service IP address (must be within service_cidr range). Leave empty to use default (10.0.0.10)."`
	// Custom DNS servers for the VNet.
	//  Leave empty to use Azure-provided DNS.
	CustomDnsServers []string `json:"custom_dns_servers,omitempty" jsonschema:"Custom DNS servers for the VNet. Leave empty to use Azure-provided DNS."`
}

func (s *AzureAksClusterAdvancedNetworkingInput) validate() error {
	return nil
}

func (s *AzureAksClusterAdvancedNetworkingInput) applyDefaults() {
}

func (s *AzureAksClusterAdvancedNetworkingInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.PodCidr != "" {
		m["pod_cidr"] = s.PodCidr
	}
	if s.ServiceCidr != "" {
		m["service_cidr"] = s.ServiceCidr
	}
	if s.DnsServiceIp != "" {
		m["dns_service_ip"] = s.DnsServiceIp
	}
	if len(s.CustomDnsServers) > 0 {
		m["custom_dns_servers"] = s.CustomDnsServers
	}
	return m
}

// Autoscaling configuration for node pools.
type AzureAksClusterAutoscalingConfigInput struct {
	// Minimum number of nodes. For system pools, minimum should be 3 for high availability.
	MinCount int32 `json:"min_count,omitempty" jsonschema:"Minimum number of nodes. For system pools; minimum should be 3 for high availability."`
	// Maximum number of nodes. Autoscaler will not scale beyond this limit.
	MaxCount int32 `json:"max_count,omitempty" jsonschema:"Maximum number of nodes. Autoscaler will not scale beyond this limit."`
}

func (s *AzureAksClusterAutoscalingConfigInput) validate() error {
	return nil
}

func (s *AzureAksClusterAutoscalingConfigInput) applyDefaults() {
}

func (s *AzureAksClusterAutoscalingConfigInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.MinCount != 0 {
		m["min_count"] = s.MinCount
	}
	if s.MaxCount != 0 {
		m["max_count"] = s.MaxCount
	}
	return m
}

// System node pool configuration.
//
//	System node pools run critical AKS components and should be isolated from application workloads.
type AzureAksClusterSystemNodePoolInput struct {
	// Azure VM size for system nodes (e.g., "Standard_D4s_v5").
	//  Minimum recommended: Standard_D2s_v3 for dev/test, Standard_D4s_v5 for production.
	VmSize string `json:"vm_size" jsonschema:"required,Azure VM size for system nodes (e.g.; 'Standard_D4s_v5'). Minimum recommended: Standard_D2s_v3 for dev/test; Standard_D4s_v5 for production."`
	// Autoscaling configuration.
	//  Production minimum: 3 nodes for high availability.
	Autoscaling *AzureAksClusterAutoscalingConfigInput `json:"autoscaling" jsonschema:"required,Autoscaling configuration. Production minimum: 3 nodes for high availability."`
	// Availability zones for the node pool (e.g., ["1", "2", "3"]).
	//  For production, deploy across 3 zones for 99.95% SLA.
	//  For dev/test, single zone (["1"]) is acceptable.
	AvailabilityZones []string `json:"availability_zones,omitempty" jsonschema:"Availability zones for the node pool (e.g.; ['1'; '2'; '3']). For production; deploy across 3 zones for 99.95% SLA. For dev/test; single zone (['1']) is acceptable."`
}

func (s *AzureAksClusterSystemNodePoolInput) validate() error {
	if s.VmSize == "" {
		return fmt.Errorf("vm_size is required")
	}
	if s.Autoscaling == nil {
		return fmt.Errorf("autoscaling is required")
	}
	if s.Autoscaling != nil {
		if err := s.Autoscaling.validate(); err != nil {
			return fmt.Errorf("autoscaling: %w", err)
		}
	}
	if len(s.AvailabilityZones) < 1 {
		return fmt.Errorf("availability_zones requires at least 1 items, got %d", len(s.AvailabilityZones))
	}
	return nil
}

func (s *AzureAksClusterSystemNodePoolInput) applyDefaults() {
	if s.Autoscaling != nil {
		s.Autoscaling.applyDefaults()
	}
}

func (s *AzureAksClusterSystemNodePoolInput) toMap() map[string]any {
	m := make(map[string]any)
	m["vm_size"] = s.VmSize
	if s.Autoscaling != nil {
		m["autoscaling"] = s.Autoscaling.toMap()
	}
	if len(s.AvailabilityZones) > 0 {
		m["availability_zones"] = s.AvailabilityZones
	}
	return m
}

// User node pool configuration for application workloads.
type AzureAksClusterUserNodePoolInput struct {
	// Name of the user node pool (e.g., "general", "compute", "memory").
	//  Must be lowercase alphanumeric, max 12 characters.
	Name string `json:"name" jsonschema:"required,Name of the user node pool (e.g.; 'general'; 'compute'; 'memory'). Must be lowercase alphanumeric; max 12 characters."`
	// Azure VM size for this node pool (e.g., "Standard_D8s_v5").
	//  Choose based on workload requirements (CPU vs memory intensive).
	VmSize string `json:"vm_size" jsonschema:"required,Azure VM size for this node pool (e.g.; 'Standard_D8s_v5'). Choose based on workload requirements (CPU vs memory intensive)."`
	// Autoscaling configuration for the user node pool.
	Autoscaling *AzureAksClusterAutoscalingConfigInput `json:"autoscaling" jsonschema:"required,Autoscaling configuration for the user node pool."`
	// Availability zones for the node pool (e.g., ["1", "2", "3"]).
	//  For production workloads, deploy across multiple zones.
	AvailabilityZones []string `json:"availability_zones,omitempty" jsonschema:"Availability zones for the node pool (e.g.; ['1'; '2'; '3']). For production workloads; deploy across multiple zones."`
	// Enable Azure Spot instances for this node pool.
	//  Spot instances provide 30-90% cost savings but can be evicted when Azure needs capacity.
	//  Only suitable for fault-tolerant, stateless workloads.
	SpotEnabled bool `json:"spot_enabled,omitempty" jsonschema:"Enable Azure Spot instances for this node pool. Spot instances provide 30-90% cost savings but can be evicted when Azure needs capacity. Only suitable for fault-tolerant; stateless workloads."`
}

func (s *AzureAksClusterUserNodePoolInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	if s.VmSize == "" {
		return fmt.Errorf("vm_size is required")
	}
	if s.Autoscaling == nil {
		return fmt.Errorf("autoscaling is required")
	}
	if s.Autoscaling != nil {
		if err := s.Autoscaling.validate(); err != nil {
			return fmt.Errorf("autoscaling: %w", err)
		}
	}
	if len(s.AvailabilityZones) < 1 {
		return fmt.Errorf("availability_zones requires at least 1 items, got %d", len(s.AvailabilityZones))
	}
	return nil
}

func (s *AzureAksClusterUserNodePoolInput) applyDefaults() {
	if s.Autoscaling != nil {
		s.Autoscaling.applyDefaults()
	}
}

func (s *AzureAksClusterUserNodePoolInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	m["vm_size"] = s.VmSize
	if s.Autoscaling != nil {
		m["autoscaling"] = s.Autoscaling.toMap()
	}
	if len(s.AvailabilityZones) > 0 {
		m["availability_zones"] = s.AvailabilityZones
	}
	if s.SpotEnabled {
		m["spot_enabled"] = s.SpotEnabled
	}
	return m
}

// ParseAzureAksCluster validates and normalizes a AzureAksCluster cloud_object.
func ParseAzureAksCluster(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "azure.openmcf.org/v1", "AzureAksCluster"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec AzureAksClusterSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
