// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-26T22:01:03+05:30

package oci

import (
	"encoding/json"
	"fmt"

	"github.com/plantoncloud/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// OciContainerEngineNodePool is the top-level resource representing an Oracle
//
//	Cloud Infrastructure Container Engine for Kubernetes (OKE) node pool.
type OciContainerEngineNodePoolSpecInput struct {
	// OCID of the compartment where the node pool will be created.
	//  Changing this after creation forces node pool recreation.
	CompartmentId string `json:"compartment_id" jsonschema:"required,OCID of the compartment where the node pool will be created. Changing this after creation forces node pool recreation."`
	// OCID of the OKE cluster to which this node pool is attached.
	//  Changing this after creation forces node pool recreation.
	ClusterId string `json:"cluster_id" jsonschema:"required,OCID of the OKE cluster to which this node pool is attached. Changing this after creation forces node pool recreation."`
	// Human-readable name for the node pool shown in the OCI Console.
	//  Falls back to metadata.name if not provided.
	Name string `json:"name,omitempty" jsonschema:"Human-readable name for the node pool shown in the OCI Console. Falls back to metadata.name if not provided."`
	// Kubernetes version for the nodes. When omitted, inherits the cluster's
	//  Kubernetes version. Set explicitly to pin a specific version or to
	//  perform a rolling version upgrade of worker nodes independently of the
	//  control plane.
	//  Example: "v1.28.2".
	KubernetesVersion string `json:"kubernetes_version,omitempty" jsonschema:"Kubernetes version for the nodes. When omitted; inherits the cluster's Kubernetes version. Set explicitly to pin a specific version or to perform a rolling version upgrade of worker nodes independentl..."`
	// Compute shape for all nodes in this pool.
	//  Example: "VM.Standard.E4.Flex", "VM.Standard.A1.Flex", "VM.GPU.A10.1".
	//  For flex shapes, also set node_shape_config to specify OCPUs and memory.
	NodeShape string `json:"node_shape,omitempty" jsonschema:"Compute shape for all nodes in this pool. Example: 'VM.Standard.E4.Flex'; 'VM.Standard.A1.Flex'; 'VM.GPU.A10.1'. For flex shapes; also set node_shape_config to specify OCPUs and memory."`
	// Shape configuration for flex shapes. Required when node_shape is a
	//  flex shape (e.g., VM.Standard.E4.Flex). Ignored for fixed shapes.
	NodeShapeConfig *NodeShapeConfigInput `json:"node_shape_config,omitempty" jsonschema:"Shape configuration for flex shapes. Required when node_shape is a flex shape (e.g.; VM.Standard.E4.Flex). Ignored for fixed shapes."`
	// OS image and boot volume configuration for nodes.
	//  When omitted, OKE uses the default Oracle Linux image for the cluster's
	//  Kubernetes version.
	NodeSourceDetails *NodeSourceDetailsInput `json:"node_source_details,omitempty" jsonschema:"OS image and boot volume configuration for nodes. When omitted; OKE uses the default Oracle Linux image for the cluster's Kubernetes version."`
	// Node placement, sizing, networking, and encryption configuration.
	NodeConfigDetails *NodeConfigDetailsInput `json:"node_config_details" jsonschema:"required,Node placement; sizing; networking; and encryption configuration."`
	// SSH public key installed on each node for debug access.
	//  The corresponding private key allows SSH to nodes via their private IP
	//  (or public IP if the subnet allows it).
	SshPublicKey string `json:"ssh_public_key,omitempty" jsonschema:"SSH public key installed on each node for debug access. The corresponding private key allows SSH to nodes via their private IP (or public IP if the subnet allows it)."`
	// Kubernetes labels applied to each node after it joins the cluster.
	//  Commonly used for scheduling constraints (nodeSelector, affinity rules).
	//  Example: [{ key: "workload-type", value: "gpu" }]
	InitialNodeLabels []*NodeLabelInput `json:"initial_node_labels,omitempty" jsonschema:"Kubernetes labels applied to each node after it joins the cluster. Commonly used for scheduling constraints (nodeSelector; affinity rules). Example: [{ key: 'workload-type'; value: 'gpu' }]"`
	// Key/value pairs added to each underlying OCI compute instance at launch.
	//  Used for cloud-init user data and instance metadata configuration.
	NodeMetadata map[string]string `json:"node_metadata,omitempty" jsonschema:"Key/value pairs added to each underlying OCI compute instance at launch. Used for cloud-init user data and instance metadata configuration."`
	// Controls graceful node eviction behavior during node pool operations
	//  (scale-down, version upgrades, shape changes).
	NodeEvictionSettings *NodeEvictionSettingsInput `json:"node_eviction_settings,omitempty" jsonschema:"Controls graceful node eviction behavior during node pool operations (scale-down; version upgrades; shape changes)."`
	// Rolling update strategy for node pool operations. Controls how many
	//  nodes can be replaced simultaneously during upgrades.
	NodePoolCyclingDetails *NodePoolCyclingDetailsInput `json:"node_pool_cycling_details,omitempty" jsonschema:"Rolling update strategy for node pool operations. Controls how many nodes can be replaced simultaneously during upgrades."`
}

func (s *OciContainerEngineNodePoolSpecInput) validate() error {
	if s.CompartmentId == "" {
		return fmt.Errorf("compartment_id is required")
	}
	if s.ClusterId == "" {
		return fmt.Errorf("cluster_id is required")
	}
	if s.NodeShapeConfig != nil {
		if err := s.NodeShapeConfig.validate(); err != nil {
			return fmt.Errorf("node_shape_config: %w", err)
		}
	}
	if s.NodeSourceDetails != nil {
		if err := s.NodeSourceDetails.validate(); err != nil {
			return fmt.Errorf("node_source_details: %w", err)
		}
	}
	if s.NodeConfigDetails == nil {
		return fmt.Errorf("node_config_details is required")
	}
	if s.NodeConfigDetails != nil {
		if err := s.NodeConfigDetails.validate(); err != nil {
			return fmt.Errorf("node_config_details: %w", err)
		}
	}
	for i, v := range s.InitialNodeLabels {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("initial_node_labels[%d]: %w", i, err)
			}
		}
	}
	if s.NodeEvictionSettings != nil {
		if err := s.NodeEvictionSettings.validate(); err != nil {
			return fmt.Errorf("node_eviction_settings: %w", err)
		}
	}
	if s.NodePoolCyclingDetails != nil {
		if err := s.NodePoolCyclingDetails.validate(); err != nil {
			return fmt.Errorf("node_pool_cycling_details: %w", err)
		}
	}
	return nil
}

func (s *OciContainerEngineNodePoolSpecInput) applyDefaults() {
	if s.NodeShapeConfig != nil {
		s.NodeShapeConfig.applyDefaults()
	}
	if s.NodeSourceDetails != nil {
		s.NodeSourceDetails.applyDefaults()
	}
	if s.NodeConfigDetails != nil {
		s.NodeConfigDetails.applyDefaults()
	}
	if s.NodeEvictionSettings != nil {
		s.NodeEvictionSettings.applyDefaults()
	}
	if s.NodePoolCyclingDetails != nil {
		s.NodePoolCyclingDetails.applyDefaults()
	}
}

func (s *OciContainerEngineNodePoolSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	m["compartment_id"] = s.CompartmentId
	m["cluster_id"] = s.ClusterId
	if s.Name != "" {
		m["name"] = s.Name
	}
	if s.KubernetesVersion != "" {
		m["kubernetes_version"] = s.KubernetesVersion
	}
	if s.NodeShape != "" {
		m["node_shape"] = s.NodeShape
	}
	if s.NodeShapeConfig != nil {
		m["node_shape_config"] = s.NodeShapeConfig.toMap()
	}
	if s.NodeSourceDetails != nil {
		m["node_source_details"] = s.NodeSourceDetails.toMap()
	}
	if s.NodeConfigDetails != nil {
		m["node_config_details"] = s.NodeConfigDetails.toMap()
	}
	if s.SshPublicKey != "" {
		m["ssh_public_key"] = s.SshPublicKey
	}
	if len(s.InitialNodeLabels) > 0 {
		items := make([]any, len(s.InitialNodeLabels))
		for i, v := range s.InitialNodeLabels {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["initial_node_labels"] = items
	}
	if len(s.NodeMetadata) > 0 {
		m["node_metadata"] = s.NodeMetadata
	}
	if s.NodeEvictionSettings != nil {
		m["node_eviction_settings"] = s.NodeEvictionSettings.toMap()
	}
	if s.NodePoolCyclingDetails != nil {
		m["node_pool_cycling_details"] = s.NodePoolCyclingDetails.toMap()
	}
	return m
}

// NodeConfigDetails controls node placement across availability domains,
//
//	pool sizing, network security groups, encryption, and pod networking.
type NodeConfigDetailsInput struct {
	// Placement configurations determining which availability domains and
	//  subnets receive nodes. Provide one entry per AD for regional subnets,
	//  or one entry per AD-specific subnet.
	PlacementConfigs []*PlacementConfigInput `json:"placement_configs,omitempty" jsonschema:"Placement configurations determining which availability domains and subnets receive nodes. Provide one entry per AD for regional subnets; or one entry per AD-specific subnet."`
	// Desired number of nodes in this pool. OKE distributes nodes across
	//  the placement configs as evenly as possible.
	Size int32 `json:"size,omitempty" jsonschema:"Desired number of nodes in this pool. OKE distributes nodes across the placement configs as evenly as possible."`
	// OCIDs of network security groups applied to the node VNICs.
	NsgIds []string `json:"nsg_ids,omitempty" jsonschema:"OCIDs of network security groups applied to the node VNICs."`
	// OCID of the KMS key for encrypting boot volumes at rest.
	//  default_kind will be updated when OciKmsKey (R25) is implemented.
	KmsKeyId string `json:"kms_key_id,omitempty" jsonschema:"OCID of the KMS key for encrypting boot volumes at rest. default_kind will be updated when OciKmsKey (R25) is implemented."`
	// Whether to enable in-transit encryption for the data volume's
	//  paravirtualized attachment. Applies to both boot and block volumes.
	IsPvEncryptionInTransitEnabled bool `json:"is_pv_encryption_in_transit_enabled,omitempty" jsonschema:"Whether to enable in-transit encryption for the data volume's paravirtualized attachment. Applies to both boot and block volumes."`
	// Pod networking configuration. Required when the cluster uses
	//  OCI VCN-native pod networking (oci_vcn_ip_native CNI).
	PodNetworkOptionDetails *PodNetworkOptionDetailsInput `json:"pod_network_option_details,omitempty" jsonschema:"Pod networking configuration. Required when the cluster uses OCI VCN-native pod networking (oci_vcn_ip_native CNI)."`
}

func (s *NodeConfigDetailsInput) validate() error {
	if len(s.PlacementConfigs) < 1 {
		return fmt.Errorf("placement_configs requires at least 1 items, got %d", len(s.PlacementConfigs))
	}
	for i, v := range s.PlacementConfigs {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("placement_configs[%d]: %w", i, err)
			}
		}
	}
	if s.PodNetworkOptionDetails != nil {
		if err := s.PodNetworkOptionDetails.validate(); err != nil {
			return fmt.Errorf("pod_network_option_details: %w", err)
		}
	}
	return nil
}

func (s *NodeConfigDetailsInput) applyDefaults() {
	if s.PodNetworkOptionDetails != nil {
		s.PodNetworkOptionDetails.applyDefaults()
	}
}

func (s *NodeConfigDetailsInput) toMap() map[string]any {
	m := make(map[string]any)
	if len(s.PlacementConfigs) > 0 {
		items := make([]any, len(s.PlacementConfigs))
		for i, v := range s.PlacementConfigs {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["placement_configs"] = items
	}
	if s.Size != 0 {
		m["size"] = s.Size
	}
	if len(s.NsgIds) > 0 {
		m["nsg_ids"] = s.NsgIds
	}
	if s.KmsKeyId != "" {
		m["kms_key_id"] = s.KmsKeyId
	}
	if s.IsPvEncryptionInTransitEnabled {
		m["is_pv_encryption_in_transit_enabled"] = s.IsPvEncryptionInTransitEnabled
	}
	if s.PodNetworkOptionDetails != nil {
		m["pod_network_option_details"] = s.PodNetworkOptionDetails.toMap()
	}
	return m
}

// NodeEvictionSettings controls how OKE drains pods from nodes during
//
//	pool operations (scale-down, upgrades, shape changes).
type NodeEvictionSettingsInput struct {
	// Maximum time OKE will attempt to evict pods before giving up.
	//  ISO 8601 duration format. Default: PT60M. Range: PT0M to PT60M.
	//  PT0M means delete the node immediately without cordon and drain.
	EvictionGraceDuration string `json:"eviction_grace_duration,omitempty" jsonschema:"Maximum time OKE will attempt to evict pods before giving up. ISO 8601 duration format. Default: PT60M. Range: PT0M to PT60M. PT0M means delete the node immediately without cordon and drain."`
	// Whether to proceed with the node action if not all pods can be
	//  evicted within the grace period.
	IsForceActionAfterGraceDuration bool `json:"is_force_action_after_grace_duration,omitempty" jsonschema:"Whether to proceed with the node action if not all pods can be evicted within the grace period."`
	// Whether to delete the underlying compute instance if pods cannot
	//  be fully evicted within the grace period.
	IsForceDeleteAfterGraceDuration bool `json:"is_force_delete_after_grace_duration,omitempty" jsonschema:"Whether to delete the underlying compute instance if pods cannot be fully evicted within the grace period."`
}

func (s *NodeEvictionSettingsInput) validate() error {
	return nil
}

func (s *NodeEvictionSettingsInput) applyDefaults() {
}

func (s *NodeEvictionSettingsInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.EvictionGraceDuration != "" {
		m["eviction_grace_duration"] = s.EvictionGraceDuration
	}
	if s.IsForceActionAfterGraceDuration {
		m["is_force_action_after_grace_duration"] = s.IsForceActionAfterGraceDuration
	}
	if s.IsForceDeleteAfterGraceDuration {
		m["is_force_delete_after_grace_duration"] = s.IsForceDeleteAfterGraceDuration
	}
	return m
}

// NodeLabel is a key/value pair applied as a Kubernetes label to each
//
//	node after it joins the cluster.
type NodeLabelInput struct {
	Key   string `json:"key,omitempty" jsonschema:""`
	Value string `json:"value,omitempty" jsonschema:""`
}

func (s *NodeLabelInput) validate() error {
	return nil
}

func (s *NodeLabelInput) applyDefaults() {
}

func (s *NodeLabelInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Key != "" {
		m["key"] = s.Key
	}
	if s.Value != "" {
		m["value"] = s.Value
	}
	return m
}

// NodePoolCyclingDetails controls the rolling update strategy when
//
//	nodes need to be replaced (e.g., during Kubernetes version upgrades
//	or shape changes).
type NodePoolCyclingDetailsInput struct {
	// Whether node cycling is enabled for this pool.
	IsNodeCyclingEnabled bool `json:"is_node_cycling_enabled,omitempty" jsonschema:"Whether node cycling is enabled for this pool."`
	// Maximum additional nodes that can be temporarily created during
	//  cycling. Accepts an integer ("1") or percentage ("25%").
	//  Default: "1".
	MaximumSurge string `json:"maximum_surge,omitempty" jsonschema:"Maximum additional nodes that can be temporarily created during cycling. Accepts an integer ('1') or percentage ('25%'). Default: '1'."`
	// Maximum nodes that can be unavailable during cycling.
	//  Accepts an integer ("0") or percentage ("25%").
	//  Default: "0".
	MaximumUnavailable string `json:"maximum_unavailable,omitempty" jsonschema:"Maximum nodes that can be unavailable during cycling. Accepts an integer ('0') or percentage ('25%'). Default: '0'."`
}

func (s *NodePoolCyclingDetailsInput) validate() error {
	return nil
}

func (s *NodePoolCyclingDetailsInput) applyDefaults() {
}

func (s *NodePoolCyclingDetailsInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.IsNodeCyclingEnabled {
		m["is_node_cycling_enabled"] = s.IsNodeCyclingEnabled
	}
	if s.MaximumSurge != "" {
		m["maximum_surge"] = s.MaximumSurge
	}
	if s.MaximumUnavailable != "" {
		m["maximum_unavailable"] = s.MaximumUnavailable
	}
	return m
}

// NodeShapeConfig specifies CPU and memory for flex compute shapes.
//
//	Flex shapes allow independent scaling of OCPUs and memory within the
//	shape's supported range. For example, VM.Standard.E4.Flex supports
//	1-64 OCPUs and 1-1024 GB memory (up to 64 GB per OCPU).
type NodeShapeConfigInput struct {
	// Number of OCPUs allocated to each node.
	//  Example: 2.0 for a 2-OCPU flex instance.
	Ocpus float32 `json:"ocpus,omitempty" jsonschema:"Number of OCPUs allocated to each node. Example: 2.0 for a 2-OCPU flex instance."`
	// Memory in gigabytes allocated to each node.
	//  Example: 32.0 for 32 GB of RAM.
	MemoryInGbs float32 `json:"memory_in_gbs,omitempty" jsonschema:"Memory in gigabytes allocated to each node. Example: 32.0 for 32 GB of RAM."`
}

func (s *NodeShapeConfigInput) validate() error {
	return nil
}

func (s *NodeShapeConfigInput) applyDefaults() {
}

func (s *NodeShapeConfigInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Ocpus != 0 {
		m["ocpus"] = s.Ocpus
	}
	if s.MemoryInGbs != 0 {
		m["memory_in_gbs"] = s.MemoryInGbs
	}
	return m
}

// NodeSourceDetails specifies the OS image for nodes.
//
//	The source_type is always "IMAGE" (the only supported type) and is
//	hardcoded by the IaC modules -- only image_id and boot volume size
//	are user-configurable.
type NodeSourceDetailsInput struct {
	// OCID of the OCI platform image or custom image for the node OS.
	//  Use `oci ce node-pool-options get` to list available images for
	//  a given Kubernetes version.
	ImageId string `json:"image_id,omitempty" jsonschema:"OCID of the OCI platform image or custom image for the node OS. Use 'oci ce node-pool-options get' to list available images for a given Kubernetes version."`
	// Boot volume size in gigabytes. Minimum 50 GB. When omitted, uses
	//  the image's default boot volume size (typically 50 GB).
	BootVolumeSizeInGbs int64 `json:"boot_volume_size_in_gbs,omitempty" jsonschema:"Boot volume size in gigabytes. Minimum 50 GB. When omitted; uses the image's default boot volume size (typically 50 GB)."`
}

func (s *NodeSourceDetailsInput) validate() error {
	return nil
}

func (s *NodeSourceDetailsInput) applyDefaults() {
}

func (s *NodeSourceDetailsInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.ImageId != "" {
		m["image_id"] = s.ImageId
	}
	if s.BootVolumeSizeInGbs != 0 {
		m["boot_volume_size_in_gbs"] = s.BootVolumeSizeInGbs
	}
	return m
}

// PlacementConfig determines where nodes are placed within OCI's
//
//	availability domain and fault domain topology.
type PlacementConfigInput struct {
	// Availability domain name where nodes will be launched.
	//  Example: "Uocm:PHX-AD-1".
	AvailabilityDomain string `json:"availability_domain,omitempty" jsonschema:"Availability domain name where nodes will be launched. Example: 'Uocm:PHX-AD-1'."`
	// OCID of the subnet in which to place nodes in this AD.
	SubnetId string `json:"subnet_id" jsonschema:"required,OCID of the subnet in which to place nodes in this AD."`
	// Fault domains within the AD to constrain node placement.
	//  When omitted, OKE distributes nodes across all fault domains.
	//  Example: ["FAULT-DOMAIN-1", "FAULT-DOMAIN-2"]
	FaultDomains []string `json:"fault_domains,omitempty" jsonschema:"Fault domains within the AD to constrain node placement. When omitted; OKE distributes nodes across all fault domains. Example: ['FAULT-DOMAIN-1'; 'FAULT-DOMAIN-2']"`
	// OCID of a compute capacity reservation to use for nodes in this AD.
	CapacityReservationId string `json:"capacity_reservation_id,omitempty" jsonschema:"OCID of a compute capacity reservation to use for nodes in this AD."`
	// Preemptible node configuration. When set, nodes in this placement
	//  use preemptible (spot) instances that can be reclaimed by OCI.
	//  Suitable for fault-tolerant and batch workloads.
	PreemptibleNodeConfig *PreemptibleNodeConfigInput `json:"preemptible_node_config,omitempty" jsonschema:"Preemptible node configuration. When set; nodes in this placement use preemptible (spot) instances that can be reclaimed by OCI. Suitable for fault-tolerant and batch workloads."`
}

func (s *PlacementConfigInput) validate() error {
	if s.SubnetId == "" {
		return fmt.Errorf("subnet_id is required")
	}
	if s.PreemptibleNodeConfig != nil {
		if err := s.PreemptibleNodeConfig.validate(); err != nil {
			return fmt.Errorf("preemptible_node_config: %w", err)
		}
	}
	return nil
}

func (s *PlacementConfigInput) applyDefaults() {
	if s.PreemptibleNodeConfig != nil {
		s.PreemptibleNodeConfig.applyDefaults()
	}
}

func (s *PlacementConfigInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.AvailabilityDomain != "" {
		m["availability_domain"] = s.AvailabilityDomain
	}
	m["subnet_id"] = s.SubnetId
	if len(s.FaultDomains) > 0 {
		m["fault_domains"] = s.FaultDomains
	}
	if s.CapacityReservationId != "" {
		m["capacity_reservation_id"] = s.CapacityReservationId
	}
	if s.PreemptibleNodeConfig != nil {
		m["preemptible_node_config"] = s.PreemptibleNodeConfig.toMap()
	}
	return m
}

// PodNetworkOptionDetails configures CNI-level pod networking for the
//
//	node pool. Required for VCN-native pod networking where each pod
//	gets a VCN IP address.
type PodNetworkOptionDetailsInput struct {
	// CNI plugin type. Must match the cluster's CNI configuration.
	CniType string `json:"cni_type,omitempty" jsonschema:"enum=flannel_overlay|oci_vcn_ip_native,CNI plugin type. Must match the cluster's CNI configuration."`
	// Maximum number of pods per node. Limited by the number of VNICs
	//  attachable to the node shape. Only applicable for oci_vcn_ip_native.
	MaxPodsPerNode int32 `json:"max_pods_per_node,omitempty" jsonschema:"Maximum number of pods per node. Limited by the number of VNICs attachable to the node shape. Only applicable for oci_vcn_ip_native."`
	// OCIDs of NSGs applied to pod VNICs. Only applicable for
	//  oci_vcn_ip_native.
	PodNsgIds []string `json:"pod_nsg_ids,omitempty" jsonschema:"OCIDs of NSGs applied to pod VNICs. Only applicable for oci_vcn_ip_native."`
	// OCIDs of subnets for pod IP allocation. Only applicable for
	//  oci_vcn_ip_native. Can be the same as or different from the node
	//  subnets.
	PodSubnetIds []string `json:"pod_subnet_ids,omitempty" jsonschema:"OCIDs of subnets for pod IP allocation. Only applicable for oci_vcn_ip_native. Can be the same as or different from the node subnets."`
}

func (s *PodNetworkOptionDetailsInput) validate() error {
	switch s.CniType {
	case "", "flannel_overlay", "oci_vcn_ip_native":
	default:
		return fmt.Errorf("invalid cni_type: %q", s.CniType)
	}
	return nil
}

func (s *PodNetworkOptionDetailsInput) applyDefaults() {
}

func (s *PodNetworkOptionDetailsInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.CniType != "" {
		m["cni_type"] = s.CniType
	}
	if s.MaxPodsPerNode != 0 {
		m["max_pods_per_node"] = s.MaxPodsPerNode
	}
	if len(s.PodNsgIds) > 0 {
		m["pod_nsg_ids"] = s.PodNsgIds
	}
	if len(s.PodSubnetIds) > 0 {
		m["pod_subnet_ids"] = s.PodSubnetIds
	}
	return m
}

// PreemptibleNodeConfig enables preemptible (spot) instances for a
//
//	placement config. Preemptible nodes are terminated when OCI reclaims
//	capacity. The preemption action is always TERMINATE (the only
//	supported action); IaC modules hardcode this.
type PreemptibleNodeConfigInput struct {
	// Whether to preserve the boot volume when the preemptible instance
	//  is terminated. Defaults to false (boot volume is deleted).
	IsPreserveBootVolume bool `json:"is_preserve_boot_volume,omitempty" jsonschema:"Whether to preserve the boot volume when the preemptible instance is terminated. Defaults to false (boot volume is deleted)."`
}

func (s *PreemptibleNodeConfigInput) validate() error {
	return nil
}

func (s *PreemptibleNodeConfigInput) applyDefaults() {
}

func (s *PreemptibleNodeConfigInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.IsPreserveBootVolume {
		m["is_preserve_boot_volume"] = s.IsPreserveBootVolume
	}
	return m
}

// ParseOciContainerEngineNodePool validates and normalizes a OciContainerEngineNodePool cloud_object.
func ParseOciContainerEngineNodePool(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "oci.openmcf.org/v1", "OciContainerEngineNodePool"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec OciContainerEngineNodePoolSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
