// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-26T22:01:03+05:30

package gcp

import (
	"encoding/json"
	"fmt"

	"github.com/plantoncloud/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// gcp-bigtable-instance
type GcpBigtableInstanceSpecInput struct {
	// GCP project where the Bigtable instance will be created.
	ProjectId string `json:"project_id" jsonschema:"required,GCP project where the Bigtable instance will be created."`
	// Name of the Bigtable instance (also called Instance ID in GCP Console).
	//  This becomes the GCP resource name and is used by Bigtable client
	//  libraries to connect. Must be 6-33 characters: lowercase letters,
	//  numbers, and hyphens only. Must start with a lowercase letter and
	//  end with a letter or numbe...
	InstanceName string `json:"instance_name" jsonschema:"required,Name of the Bigtable instance (also called Instance ID in GCP Console). This becomes the GCP resource name and is used by Bigtable client libraries to connect. Must be 6-33 characters: lowercase lette..."`
	// Human-readable display name for the instance.
	//  If not specified, defaults to the instance_name value.
	DisplayName string `json:"display_name,omitempty" jsonschema:"Human-readable display name for the instance. If not specified; defaults to the instance_name value."`
	// Whether deletion protection is enabled. When true, the instance
	//  cannot be destroyed without first setting this to false.
	//  Strongly recommended for production instances.
	//  Default: true.
	DeletionProtection bool `json:"deletion_protection,omitempty" jsonschema:"Whether deletion protection is enabled. When true; the instance cannot be destroyed without first setting this to false. Strongly recommended for production instances. Default: true."`
	// Whether to delete all backups in the instance when destroying it.
	//  Bigtable blocks instance deletion if backups exist unless this is
	//  set to true. Only relevant during destroy operations.
	ForceDestroy bool `json:"force_destroy,omitempty" jsonschema:"Whether to delete all backups in the instance when destroying it. Bigtable blocks instance deletion if backups exist unless this is set to true. Only relevant during destroy operations."`
	// One or more clusters that serve as physical replicas for this instance.
	//  Each cluster must be in a different zone within the same or different
	//  regions. At least one cluster is required. Up to 8 clusters can be
	//  configured across cloud regions for multi-region replication.
	Clusters []*GcpBigtableInstanceClusterInput `json:"clusters,omitempty" jsonschema:"One or more clusters that serve as physical replicas for this instance. Each cluster must be in a different zone within the same or different regions. At least one cluster is required. Up to 8 cluster..."`
}

func (s *GcpBigtableInstanceSpecInput) validate() error {
	if s.ProjectId == "" {
		return fmt.Errorf("project_id is required")
	}
	if s.InstanceName == "" {
		return fmt.Errorf("instance_name is required")
	}
	if len(s.Clusters) < 1 {
		return fmt.Errorf("clusters requires at least 1 items, got %d", len(s.Clusters))
	}
	for i, v := range s.Clusters {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("clusters[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *GcpBigtableInstanceSpecInput) applyDefaults() {
	// default: DeletionProtection = true (applied at zero-value)
}

func (s *GcpBigtableInstanceSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	m["project_id"] = s.ProjectId
	m["instance_name"] = s.InstanceName
	if s.DisplayName != "" {
		m["display_name"] = s.DisplayName
	}
	if s.DeletionProtection {
		m["deletion_protection"] = s.DeletionProtection
	}
	if s.ForceDestroy {
		m["force_destroy"] = s.ForceDestroy
	}
	if len(s.Clusters) > 0 {
		items := make([]any, len(s.Clusters))
		for i, v := range s.Clusters {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["clusters"] = items
	}
	return m
}

// GcpBigtableInstanceCluster defines the configuration for a single
//
//	Bigtable cluster within the instance. Each cluster serves as an
//	independent replica of the instance's data and must be placed in
//	a different zone.
//
//	Bigtable supports two scaling modes per cluster:
//
//	  - Fixed: Set num_nodes to a specific value (e.g., 3 nodes).
//	  - Autoscaling: Configure autoscaling_config with CPU/storage targets
//	    and min/max node bounds.
//
//	These are mutually exclusive. If neither is set, Bigtable automatically
//	allocates nodes based on the data footprint, optimized for 50% storage
//	utilization.
//
//	Important: zone, storage_type, kms_key_name, and node_scaling_factor
//	are immutable after creation. Changing them requires deleting and
//	recreating the cluster, which recreates the entire instance.
type GcpBigtableInstanceClusterInput struct {
	// Unique identifier for this cluster within the instance.
	//  Must be 6-30 characters: lowercase letters, numbers, and hyphens only.
	//  Must start with a lowercase letter and end with a letter or number.
	ClusterId string `json:"cluster_id" jsonschema:"required,Unique identifier for this cluster within the instance. Must be 6-30 characters: lowercase letters; numbers; and hyphens only. Must start with a lowercase letter and end with a letter or number."`
	// Zone where this cluster will be deployed (e.g., "us-central1-a").
	//  Each cluster in the instance must be in a different zone.
	//  Zones must be Bigtable-capable (see GCP Bigtable locations).
	//  Immutable after creation.
	Zone string `json:"zone" jsonschema:"required,Zone where this cluster will be deployed (e.g.; 'us-central1-a'). Each cluster in the instance must be in a different zone. Zones must be Bigtable-capable (see GCP Bigtable locations). Immutable after..."`
	// Fixed number of nodes in this cluster. Mutually exclusive with
	//  autoscaling_config. If neither is set, Bigtable auto-allocates
	//  nodes based on the data footprint.
	NumNodes int32 `json:"num_nodes,omitempty" jsonschema:"Fixed number of nodes in this cluster. Mutually exclusive with autoscaling_config. If neither is set; Bigtable auto-allocates nodes based on the data footprint."`
	// Storage type for this cluster.
	//  SSD: lower latency, recommended for most workloads.
	//  HDD: lower cost, suitable for large batch-analytics workloads
	//  where latency is less critical.
	//  Default: SSD.
	//  Immutable after creation.
	StorageType string `json:"storage_type,omitempty" jsonschema:"Storage type for this cluster. SSD: lower latency; recommended for most workloads. HDD: lower cost; suitable for large batch-analytics workloads where latency is less critical. Default: SSD. Immutable..."`
	// Cloud KMS encryption key to protect data in this cluster (CMEK).
	//  Format: projects/{project}/locations/{location}/keyRings/{keyring}/cryptoKeys/{key}
	//  The key region must match the cluster zone's region. All clusters
	//  within an instance should use the same CMEK key.
	//  Immutable after creation.
	KmsKeyName string `json:"kms_key_name,omitempty" jsonschema:"Cloud KMS encryption key to protect data in this cluster (CMEK). Format: projects/{project}/locations/{location}/keyRings/{keyring}/cryptoKeys/{key} The key region must match the cluster zone's region..."`
	// Node scaling factor for this cluster. Controls the granularity of
	//  node scaling: 1X scales in increments of 1 node, 2X scales in
	//  increments of 2 nodes (for larger workloads that benefit from
	//  coarser scaling steps). When using 2X, num_nodes, min_nodes, and
	//  max_nodes must all be specified in increm...
	NodeScalingFactor string `json:"node_scaling_factor,omitempty" jsonschema:"Node scaling factor for this cluster. Controls the granularity of node scaling: 1X scales in increments of 1 node; 2X scales in increments of 2 nodes (for larger workloads that benefit from coarser sc..."`
	// Autoscaling configuration for this cluster. Mutually exclusive with
	//  num_nodes. When set, Bigtable dynamically adjusts the number of
	//  nodes based on CPU and storage utilization targets.
	AutoscalingConfig *GcpBigtableInstanceClusterAutoscalingConfigInput `json:"autoscaling_config,omitempty" jsonschema:"Autoscaling configuration for this cluster. Mutually exclusive with num_nodes. When set; Bigtable dynamically adjusts the number of nodes based on CPU and storage utilization targets."`
}

func (s *GcpBigtableInstanceClusterInput) validate() error {
	if s.ClusterId == "" {
		return fmt.Errorf("cluster_id is required")
	}
	if s.Zone == "" {
		return fmt.Errorf("zone is required")
	}
	if s.AutoscalingConfig != nil {
		if err := s.AutoscalingConfig.validate(); err != nil {
			return fmt.Errorf("autoscaling_config: %w", err)
		}
	}
	return nil
}

func (s *GcpBigtableInstanceClusterInput) applyDefaults() {
	if s.StorageType == "" {
		s.StorageType = "SSD"
	}
	if s.AutoscalingConfig != nil {
		s.AutoscalingConfig.applyDefaults()
	}
}

func (s *GcpBigtableInstanceClusterInput) toMap() map[string]any {
	m := make(map[string]any)
	m["cluster_id"] = s.ClusterId
	m["zone"] = s.Zone
	if s.NumNodes != 0 {
		m["num_nodes"] = s.NumNodes
	}
	if s.StorageType != "" {
		m["storage_type"] = s.StorageType
	}
	if s.KmsKeyName != "" {
		m["kms_key_name"] = s.KmsKeyName
	}
	if s.NodeScalingFactor != "" {
		m["node_scaling_factor"] = s.NodeScalingFactor
	}
	if s.AutoscalingConfig != nil {
		m["autoscaling_config"] = s.AutoscalingConfig.toMap()
	}
	return m
}

// GcpBigtableInstanceClusterAutoscalingConfig defines the autoscaling
//
//	parameters for a Bigtable cluster. When configured, Bigtable dynamically
//	adjusts the number of nodes based on CPU and storage utilization.
//
//	Autoscaling is mutually exclusive with fixed num_nodes on the parent
//	cluster message. When autoscaling is configured, any num_nodes value
//	on the cluster is ignored.
type GcpBigtableInstanceClusterAutoscalingConfigInput struct {
	// Minimum number of nodes for autoscaling. Must be at least 1.
	MinNodes int32 `json:"min_nodes" jsonschema:"required,Minimum number of nodes for autoscaling. Must be at least 1."`
	// Maximum number of nodes for autoscaling. Must be at least 1 and
	//  greater than or equal to min_nodes.
	MaxNodes int32 `json:"max_nodes" jsonschema:"required,Maximum number of nodes for autoscaling. Must be at least 1 and greater than or equal to min_nodes."`
	// Target CPU utilization percentage for autoscaling. Bigtable adds nodes
	//  when average CPU utilization exceeds this target and removes nodes
	//  when utilization drops sufficiently below it. Must be between 10 and 80.
	CpuTarget int32 `json:"cpu_target" jsonschema:"required,Target CPU utilization percentage for autoscaling. Bigtable adds nodes when average CPU utilization exceeds this target and removes nodes when utilization drops sufficiently below it. Must be between ..."`
	// Target storage utilization per node in GB. When total storage per node
	//  exceeds this target, Bigtable adds nodes. The valid range depends on
	//  the cluster's storage_type:
	//    - SSD: 2560 to 5120 (2.5 TiB to 5 TiB per node)
	//    - HDD: 8192 to 16384 (8 TiB to 16 TiB per node)
	//  If not set, Bigtable uses t...
	StorageTarget int32 `json:"storage_target,omitempty" jsonschema:"Target storage utilization per node in GB. When total storage per node exceeds this target; Bigtable adds nodes. The valid range depends on the cluster's storage_type: - SSD: 2560 to 5120 (2.5 TiB to ..."`
}

func (s *GcpBigtableInstanceClusterAutoscalingConfigInput) validate() error {
	return nil
}

func (s *GcpBigtableInstanceClusterAutoscalingConfigInput) applyDefaults() {
}

func (s *GcpBigtableInstanceClusterAutoscalingConfigInput) toMap() map[string]any {
	m := make(map[string]any)
	m["min_nodes"] = s.MinNodes
	m["max_nodes"] = s.MaxNodes
	m["cpu_target"] = s.CpuTarget
	if s.StorageTarget != 0 {
		m["storage_target"] = s.StorageTarget
	}
	return m
}

// ParseGcpBigtableInstance validates and normalizes a GcpBigtableInstance cloud_object.
func ParseGcpBigtableInstance(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "gcp.openmcf.org/v1", "GcpBigtableInstance"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec GcpBigtableInstanceSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
