// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-26T21:50:49+05:30

package aws

import (
	"encoding/json"
	"fmt"

	"github.com/plantoncloud/mcp-server-planton/gen/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// AwsCodePipeline is a deployment component for creating and managing
//
//	AWS CodePipeline continuous delivery pipelines that orchestrate build,
//	test, and deploy phases of your release process through an ordered
//	sequence of stages and actions.
type AwsCodePipelineSpecInput struct {
	// The AWS region where the resource will be created.
	//  Example: "us-west-2", "eu-west-1"
	Region string `json:"region,omitempty" jsonschema:"The AWS region where the resource will be created. Example: 'us-west-2'; 'eu-west-1'"`
	// pipeline_type selects the pipeline version.
	//    V1: Legacy pipeline (no triggers, no variables, SUPERSEDED execution only)
	//    V2: Modern pipeline with triggers, variables, and advanced execution modes
	//  Default: V2 (recommended for all new pipelines).
	PipelineType string `json:"pipeline_type,omitempty" jsonschema:"pipeline_type selects the pipeline version. V1: Legacy pipeline (no triggers; no variables; SUPERSEDED execution only) V2: Modern pipeline with triggers; variables; and advanced execution modes Defaul..."`
	// execution_mode controls how concurrent pipeline executions are handled.
	//    SUPERSEDED: New execution supersedes any in-progress execution (default)
	//    QUEUED:     New executions queue behind the current one (V2 only)
	//    PARALLEL:   Executions run simultaneously without waiting (V2 only)
	//  Default: SU...
	ExecutionMode string `json:"execution_mode,omitempty" jsonschema:"execution_mode controls how concurrent pipeline executions are handled. SUPERSEDED: New execution supersedes any in-progress execution (default) QUEUED: New executions queue behind the current one (V2..."`
	// role_arn is the IAM role ARN that grants CodePipeline permission to
	//  access source providers, invoke build/deploy actions, and manage
	//  artifacts in S3. This role must have policies for every action provider
	//  used in the pipeline (e.g., CodeBuild, S3, ECS, Lambda).
	RoleArn string `json:"role_arn" jsonschema:"required,role_arn is the IAM role ARN that grants CodePipeline permission to access source providers; invoke build/deploy actions; and manage artifacts in S3. This role must have policies for every action prov..."`
	// artifact_stores define S3 buckets where pipeline artifacts are stored.
	//  For single-region pipelines, provide exactly one store without a region.
	//  For cross-region pipelines, provide one store per region (each with a
	//  region field) so that actions in different regions have local artifact
	//  access.
	ArtifactStores []*AwsCodePipelineArtifactStoreInput `json:"artifact_stores" jsonschema:"required,artifact_stores define S3 buckets where pipeline artifacts are stored. For single-region pipelines; provide exactly one store without a region. For cross-region pipelines; provide one store per region..."`
	// stages define the ordered sequence of pipeline stages. Each stage
	//  contains one or more actions that run in parallel (same run_order)
	//  or sequentially (different run_order values).
	//  A pipeline requires at minimum two stages: a source stage and at
	//  least one build, test, deploy, or approval stage.
	Stages []*AwsCodePipelineStageInput `json:"stages" jsonschema:"required,stages define the ordered sequence of pipeline stages. Each stage contains one or more actions that run in parallel (same run_order) or sequentially (different run_order values). A pipeline requires a..."`
	// triggers define automatic pipeline execution rules based on git events.
	//  V2 pipelines only. Triggers use CodeStar Connections to listen for
	//  push or pull request events on source repositories with branch, tag,
	//  and file path filtering.
	Triggers []*AwsCodePipelineTriggerInput `json:"triggers,omitempty" jsonschema:"triggers define automatic pipeline execution rules based on git events. V2 pipelines only. Triggers use CodeStar Connections to listen for push or pull request events on source repositories with branc..."`
	// variables define pipeline-level parameters that can be referenced in
	//  action configurations using #{variables.VariableName} syntax.
	//  V2 pipelines only.
	Variables []*AwsCodePipelineVariableInput `json:"variables,omitempty" jsonschema:"variables define pipeline-level parameters that can be referenced in action configurations using #{variables.VariableName} syntax. V2 pipelines only."`
}

func (s *AwsCodePipelineSpecInput) validate() error {
	if s.RoleArn == "" {
		return fmt.Errorf("role_arn is required")
	}
	if len(s.ArtifactStores) == 0 {
		return fmt.Errorf("artifact_stores is required")
	}
	if len(s.ArtifactStores) < 1 {
		return fmt.Errorf("artifact_stores requires at least 1 items, got %d", len(s.ArtifactStores))
	}
	for i, v := range s.ArtifactStores {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("artifact_stores[%d]: %w", i, err)
			}
		}
	}
	if len(s.Stages) == 0 {
		return fmt.Errorf("stages is required")
	}
	if len(s.Stages) < 2 {
		return fmt.Errorf("stages requires at least 2 items, got %d", len(s.Stages))
	}
	for i, v := range s.Stages {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("stages[%d]: %w", i, err)
			}
		}
	}
	for i, v := range s.Triggers {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("triggers[%d]: %w", i, err)
			}
		}
	}
	for i, v := range s.Variables {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("variables[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsCodePipelineSpecInput) applyDefaults() {
	if s.PipelineType == "" {
		s.PipelineType = "V2"
	}
	if s.ExecutionMode == "" {
		s.ExecutionMode = "SUPERSEDED"
	}
}

func (s *AwsCodePipelineSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Region != "" {
		m["region"] = s.Region
	}
	if s.PipelineType != "" {
		m["pipeline_type"] = s.PipelineType
	}
	if s.ExecutionMode != "" {
		m["execution_mode"] = s.ExecutionMode
	}
	m["role_arn"] = s.RoleArn
	if len(s.ArtifactStores) > 0 {
		items := make([]any, len(s.ArtifactStores))
		for i, v := range s.ArtifactStores {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["artifact_stores"] = items
	}
	if len(s.Stages) > 0 {
		items := make([]any, len(s.Stages))
		for i, v := range s.Stages {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["stages"] = items
	}
	if len(s.Triggers) > 0 {
		items := make([]any, len(s.Triggers))
		for i, v := range s.Triggers {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["triggers"] = items
	}
	if len(s.Variables) > 0 {
		items := make([]any, len(s.Variables))
		for i, v := range s.Variables {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["variables"] = items
	}
	return m
}

// AwsCodePipelineAction defines a single action within a pipeline stage.
//
//	Actions are the building blocks of a pipeline — each action connects to
//	a provider (CodeBuild, S3, Lambda, ECS, etc.) and performs a specific
//	task in the release process.
type AwsCodePipelineActionInput struct {
	// name is the action name. Must be unique within the stage.
	Name string `json:"name" jsonschema:"required,name is the action name. Must be unique within the stage."`
	// category classifies the action type.
	//    Source:   Fetches source code or artifacts from a provider
	//    Build:    Compiles, tests, or transforms code
	//    Test:     Runs test suites
	//    Deploy:   Deploys artifacts to a target environment
	//    Approval: Requires manual approval before proceeding
	//    Invoke: ...
	Category string `json:"category" jsonschema:"required,category classifies the action type. Source: Fetches source code or artifacts from a provider Build: Compiles; tests; or transforms code Test: Runs test suites Deploy: Deploys artifacts to a target en..."`
	// owner identifies who created the action type.
	//    AWS:        Built-in AWS actions (CodeBuild, S3, ECS, Lambda, etc.)
	//    ThirdParty: Third-party integrations (GitHub v1, etc.)
	//    Custom:     User-defined custom action types
	Owner string `json:"owner" jsonschema:"required,owner identifies who created the action type. AWS: Built-in AWS actions (CodeBuild; S3; ECS; Lambda; etc.) ThirdParty: Third-party integrations (GitHub v1; etc.) Custom: User-defined custom action typ..."`
	// provider is the service that performs the action. The valid values
	//  depend on the category and owner combination. Common providers:
	//    Source:   CodeStarSourceConnection, S3, ECR, CodeCommit
	//    Build:    CodeBuild
	//    Test:     CodeBuild, DeviceFarm
	//    Deploy:   S3, CodeDeploy, CloudFormation, ECS, E...
	Provider string `json:"provider" jsonschema:"required,provider is the service that performs the action. The valid values depend on the category and owner combination. Common providers: Source: CodeStarSourceConnection; S3; ECR; CodeCommit Build: CodeBuil..."`
	// version is the action type version. Typically "1" for all built-in actions.
	Version string `json:"version" jsonschema:"required,version is the action type version. Typically '1' for all built-in actions."`
	// configuration contains provider-specific key-value pairs that control
	//  the action's behavior. Each provider expects different keys.
	//
	//  Common examples:
	//    CodeStarSourceConnection: ConnectionArn, FullRepositoryId, BranchName,
	//                              OutputArtifactFormat, DetectChanges
	//    CodeBui...
	Configuration map[string]string `json:"configuration,omitempty" jsonschema:"configuration contains provider-specific key-value pairs that control the action's behavior. Each provider expects different keys. Common examples: CodeStarSourceConnection: ConnectionArn; FullReposit..."`
	// input_artifacts are artifact names from previous stages or actions
	//  that this action consumes. For Source actions, this is typically empty.
	InputArtifacts []string `json:"input_artifacts,omitempty" jsonschema:"input_artifacts are artifact names from previous stages or actions that this action consumes. For Source actions; this is typically empty."`
	// output_artifacts are artifact names that this action produces for
	//  consumption by downstream stages or actions.
	OutputArtifacts []string `json:"output_artifacts,omitempty" jsonschema:"output_artifacts are artifact names that this action produces for consumption by downstream stages or actions."`
	// namespace defines a variable namespace for this action's output variables.
	//  Other actions can reference these variables as #{namespace.VariableName}.
	//  Only meaningful for actions that produce output variables (e.g., source actions).
	Namespace string `json:"namespace,omitempty" jsonschema:"namespace defines a variable namespace for this action's output variables. Other actions can reference these variables as #{namespace.VariableName}. Only meaningful for actions that produce output var..."`
	// region is the AWS region where this action executes. Required for
	//  cross-region actions. If omitted, the action runs in the pipeline's region.
	Region string `json:"region,omitempty" jsonschema:"region is the AWS region where this action executes. Required for cross-region actions. If omitted; the action runs in the pipeline's region."`
	// role_arn is an IAM role ARN that the action assumes instead of the
	//  pipeline's role. Useful for cross-account deployments or when an action
	//  needs different permissions than the pipeline role.
	RoleArn string `json:"role_arn,omitempty" jsonschema:"role_arn is an IAM role ARN that the action assumes instead of the pipeline's role. Useful for cross-account deployments or when an action needs different permissions than the pipeline role."`
	// run_order controls execution order within a stage. Actions with the
	//  same run_order execute in parallel. Lower values run first.
	//  Range: 1-999. Default: 1 (all actions parallel).
	RunOrder int32 `json:"run_order,omitempty" jsonschema:"run_order controls execution order within a stage. Actions with the same run_order execute in parallel. Lower values run first. Range: 1-999. Default: 1 (all actions parallel)."`
	// timeout_in_minutes is the maximum time an action can run before timing out.
	//  Range: 5-86400 (60 days). If omitted, the action uses the provider default.
	TimeoutInMinutes int32 `json:"timeout_in_minutes,omitempty" jsonschema:"timeout_in_minutes is the maximum time an action can run before timing out. Range: 5-86400 (60 days). If omitted; the action uses the provider default."`
}

func (s *AwsCodePipelineActionInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	if s.Category == "" {
		return fmt.Errorf("category is required")
	}
	if s.Owner == "" {
		return fmt.Errorf("owner is required")
	}
	if s.Provider == "" {
		return fmt.Errorf("provider is required")
	}
	if s.Version == "" {
		return fmt.Errorf("version is required")
	}
	return nil
}

func (s *AwsCodePipelineActionInput) applyDefaults() {
}

func (s *AwsCodePipelineActionInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	m["category"] = s.Category
	m["owner"] = s.Owner
	m["provider"] = s.Provider
	m["version"] = s.Version
	if len(s.Configuration) > 0 {
		m["configuration"] = s.Configuration
	}
	if len(s.InputArtifacts) > 0 {
		m["input_artifacts"] = s.InputArtifacts
	}
	if len(s.OutputArtifacts) > 0 {
		m["output_artifacts"] = s.OutputArtifacts
	}
	if s.Namespace != "" {
		m["namespace"] = s.Namespace
	}
	if s.Region != "" {
		m["region"] = s.Region
	}
	if s.RoleArn != "" {
		m["role_arn"] = s.RoleArn
	}
	if s.RunOrder != 0 {
		m["run_order"] = s.RunOrder
	}
	if s.TimeoutInMinutes != 0 {
		m["timeout_in_minutes"] = s.TimeoutInMinutes
	}
	return m
}

// AwsCodePipelineArtifactStore defines an S3 bucket used to store pipeline
//
//	artifacts (source code, build outputs) between stages.
type AwsCodePipelineArtifactStoreInput struct {
	// location is the S3 bucket name for artifact storage.
	Location string `json:"location" jsonschema:"required,location is the S3 bucket name for artifact storage."`
	// region is the AWS region for this artifact store. Required only for
	//  cross-region pipelines. For single-region pipelines, omit this field.
	Region string `json:"region,omitempty" jsonschema:"region is the AWS region for this artifact store. Required only for cross-region pipelines. For single-region pipelines; omit this field."`
	// encryption_key_id is the KMS key ARN or ID used to encrypt artifacts.
	//  If omitted, the default AWS-managed S3 encryption key is used.
	EncryptionKeyId string `json:"encryption_key_id,omitempty" jsonschema:"encryption_key_id is the KMS key ARN or ID used to encrypt artifacts. If omitted; the default AWS-managed S3 encryption key is used."`
}

func (s *AwsCodePipelineArtifactStoreInput) validate() error {
	if s.Location == "" {
		return fmt.Errorf("location is required")
	}
	return nil
}

func (s *AwsCodePipelineArtifactStoreInput) applyDefaults() {
}

func (s *AwsCodePipelineArtifactStoreInput) toMap() map[string]any {
	m := make(map[string]any)
	m["location"] = s.Location
	if s.Region != "" {
		m["region"] = s.Region
	}
	if s.EncryptionKeyId != "" {
		m["encryption_key_id"] = s.EncryptionKeyId
	}
	return m
}

// AwsCodePipelineGitConfiguration defines git event filters for a trigger.
//
//	At least one push or pull_request filter must be specified.
type AwsCodePipelineGitConfigurationInput struct {
	// source_action_name must match the name of a Source action in the first
	//  stage that uses a CodeStarSourceConnection provider.
	SourceActionName string `json:"source_action_name" jsonschema:"required,source_action_name must match the name of a Source action in the first stage that uses a CodeStarSourceConnection provider."`
	// push defines filters for git push events (branch pushes, tag pushes).
	//  Multiple push filters are OR'd — a push triggers the pipeline if ANY
	//  filter matches.
	Push []*AwsCodePipelineGitPushInput `json:"push,omitempty" jsonschema:"push defines filters for git push events (branch pushes; tag pushes). Multiple push filters are OR'd — a push triggers the pipeline if ANY filter matches."`
	// pull_request defines filters for pull request events (open, update, close).
	//  Multiple PR filters are OR'd.
	PullRequest []*AwsCodePipelineGitPullRequestInput `json:"pull_request,omitempty" jsonschema:"pull_request defines filters for pull request events (open; update; close). Multiple PR filters are OR'd."`
}

func (s *AwsCodePipelineGitConfigurationInput) validate() error {
	if s.SourceActionName == "" {
		return fmt.Errorf("source_action_name is required")
	}
	for i, v := range s.Push {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("push[%d]: %w", i, err)
			}
		}
	}
	for i, v := range s.PullRequest {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("pull_request[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsCodePipelineGitConfigurationInput) applyDefaults() {
}

func (s *AwsCodePipelineGitConfigurationInput) toMap() map[string]any {
	m := make(map[string]any)
	m["source_action_name"] = s.SourceActionName
	if len(s.Push) > 0 {
		items := make([]any, len(s.Push))
		for i, v := range s.Push {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["push"] = items
	}
	if len(s.PullRequest) > 0 {
		items := make([]any, len(s.PullRequest))
		for i, v := range s.PullRequest {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["pull_request"] = items
	}
	return m
}

// AwsCodePipelineGitFilter provides include and exclude patterns for
//
//	git-based trigger filtering. Patterns use glob syntax.
type AwsCodePipelineGitFilterInput struct {
	// includes are glob patterns that must match for the filter to pass.
	//  At least one include pattern must match.
	Includes []string `json:"includes,omitempty" jsonschema:"includes are glob patterns that must match for the filter to pass. At least one include pattern must match."`
	// excludes are glob patterns that cause the filter to reject a match.
	//  Exclusions take precedence over inclusions.
	Excludes []string `json:"excludes,omitempty" jsonschema:"excludes are glob patterns that cause the filter to reject a match. Exclusions take precedence over inclusions."`
}

func (s *AwsCodePipelineGitFilterInput) validate() error {
	return nil
}

func (s *AwsCodePipelineGitFilterInput) applyDefaults() {
}

func (s *AwsCodePipelineGitFilterInput) toMap() map[string]any {
	m := make(map[string]any)
	if len(s.Includes) > 0 {
		m["includes"] = s.Includes
	}
	if len(s.Excludes) > 0 {
		m["excludes"] = s.Excludes
	}
	return m
}

// AwsCodePipelineGitPullRequest defines filters for pull request events.
//
//	All specified filter types within a single block are AND'd together.
type AwsCodePipelineGitPullRequestInput struct {
	// branches filters by target branch name patterns (glob syntax).
	Branches *AwsCodePipelineGitFilterInput `json:"branches,omitempty" jsonschema:"branches filters by target branch name patterns (glob syntax)."`
	// file_paths filters by changed file path patterns (glob syntax).
	FilePaths *AwsCodePipelineGitFilterInput `json:"file_paths,omitempty" jsonschema:"file_paths filters by changed file path patterns (glob syntax)."`
	// events specifies which PR lifecycle events trigger the pipeline.
	//  Valid values: OPEN, UPDATE, CLOSED.
	Events []string `json:"events,omitempty" jsonschema:"events specifies which PR lifecycle events trigger the pipeline. Valid values: OPEN; UPDATE; CLOSED."`
}

func (s *AwsCodePipelineGitPullRequestInput) validate() error {
	if s.Branches != nil {
		if err := s.Branches.validate(); err != nil {
			return fmt.Errorf("branches: %w", err)
		}
	}
	if s.FilePaths != nil {
		if err := s.FilePaths.validate(); err != nil {
			return fmt.Errorf("file_paths: %w", err)
		}
	}
	return nil
}

func (s *AwsCodePipelineGitPullRequestInput) applyDefaults() {
	if s.Branches != nil {
		s.Branches.applyDefaults()
	}
	if s.FilePaths != nil {
		s.FilePaths.applyDefaults()
	}
}

func (s *AwsCodePipelineGitPullRequestInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Branches != nil {
		m["branches"] = s.Branches.toMap()
	}
	if s.FilePaths != nil {
		m["file_paths"] = s.FilePaths.toMap()
	}
	if len(s.Events) > 0 {
		m["events"] = s.Events
	}
	return m
}

// AwsCodePipelineGitPush defines filters for git push events. All specified
//
//	filter types within a single push block are AND'd together.
type AwsCodePipelineGitPushInput struct {
	// branches filters by branch name patterns (glob syntax).
	Branches *AwsCodePipelineGitFilterInput `json:"branches,omitempty" jsonschema:"branches filters by branch name patterns (glob syntax)."`
	// file_paths filters by changed file path patterns (glob syntax).
	FilePaths *AwsCodePipelineGitFilterInput `json:"file_paths,omitempty" jsonschema:"file_paths filters by changed file path patterns (glob syntax)."`
	// tags filters by tag name patterns (glob syntax).
	Tags *AwsCodePipelineGitFilterInput `json:"tags,omitempty" jsonschema:"tags filters by tag name patterns (glob syntax)."`
}

func (s *AwsCodePipelineGitPushInput) validate() error {
	if s.Branches != nil {
		if err := s.Branches.validate(); err != nil {
			return fmt.Errorf("branches: %w", err)
		}
	}
	if s.FilePaths != nil {
		if err := s.FilePaths.validate(); err != nil {
			return fmt.Errorf("file_paths: %w", err)
		}
	}
	if s.Tags != nil {
		if err := s.Tags.validate(); err != nil {
			return fmt.Errorf("tags: %w", err)
		}
	}
	return nil
}

func (s *AwsCodePipelineGitPushInput) applyDefaults() {
	if s.Branches != nil {
		s.Branches.applyDefaults()
	}
	if s.FilePaths != nil {
		s.FilePaths.applyDefaults()
	}
	if s.Tags != nil {
		s.Tags.applyDefaults()
	}
}

func (s *AwsCodePipelineGitPushInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Branches != nil {
		m["branches"] = s.Branches.toMap()
	}
	if s.FilePaths != nil {
		m["file_paths"] = s.FilePaths.toMap()
	}
	if s.Tags != nil {
		m["tags"] = s.Tags.toMap()
	}
	return m
}

// AwsCodePipelineStage defines a stage in the pipeline. Stages execute in
//
//	the order they are listed. Each stage contains one or more actions.
type AwsCodePipelineStageInput struct {
	// name is the stage name. Must be unique within the pipeline.
	//  Pattern: alphanumeric, dots, at-signs, hyphens, underscores (1-100 chars).
	Name string `json:"name" jsonschema:"required,name is the stage name. Must be unique within the pipeline. Pattern: alphanumeric; dots; at-signs; hyphens; underscores (1-100 chars)."`
	// actions define the operations performed in this stage. Actions with
	//  the same run_order execute in parallel; different run_order values
	//  execute sequentially within the stage.
	Actions []*AwsCodePipelineActionInput `json:"actions" jsonschema:"required,actions define the operations performed in this stage. Actions with the same run_order execute in parallel; different run_order values execute sequentially within the stage."`
}

func (s *AwsCodePipelineStageInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	if len(s.Actions) == 0 {
		return fmt.Errorf("actions is required")
	}
	if len(s.Actions) < 1 {
		return fmt.Errorf("actions requires at least 1 items, got %d", len(s.Actions))
	}
	for i, v := range s.Actions {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("actions[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsCodePipelineStageInput) applyDefaults() {
}

func (s *AwsCodePipelineStageInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	if len(s.Actions) > 0 {
		items := make([]any, len(s.Actions))
		for i, v := range s.Actions {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["actions"] = items
	}
	return m
}

// AwsCodePipelineTrigger defines an automatic pipeline execution trigger
//
//	based on git events. V2 pipelines only.
type AwsCodePipelineTriggerInput struct {
	// provider_type is the trigger provider. Currently only
	//  CodeStarSourceConnection is supported.
	ProviderType string `json:"provider_type" jsonschema:"required,provider_type is the trigger provider. Currently only CodeStarSourceConnection is supported."`
	// git_configuration defines the git event filters that trigger the pipeline.
	GitConfiguration *AwsCodePipelineGitConfigurationInput `json:"git_configuration" jsonschema:"required,git_configuration defines the git event filters that trigger the pipeline."`
}

func (s *AwsCodePipelineTriggerInput) validate() error {
	if s.ProviderType == "" {
		return fmt.Errorf("provider_type is required")
	}
	if s.GitConfiguration == nil {
		return fmt.Errorf("git_configuration is required")
	}
	if s.GitConfiguration != nil {
		if err := s.GitConfiguration.validate(); err != nil {
			return fmt.Errorf("git_configuration: %w", err)
		}
	}
	return nil
}

func (s *AwsCodePipelineTriggerInput) applyDefaults() {
	if s.GitConfiguration != nil {
		s.GitConfiguration.applyDefaults()
	}
}

func (s *AwsCodePipelineTriggerInput) toMap() map[string]any {
	m := make(map[string]any)
	m["provider_type"] = s.ProviderType
	if s.GitConfiguration != nil {
		m["git_configuration"] = s.GitConfiguration.toMap()
	}
	return m
}

// AwsCodePipelineVariable defines a pipeline-level variable that can be
//
//	referenced in action configurations. V2 pipelines only.
type AwsCodePipelineVariableInput struct {
	// name is the variable name. Referenced in action configurations as
	//  #{variables.Name}.
	Name string `json:"name" jsonschema:"required,name is the variable name. Referenced in action configurations as #{variables.Name}."`
	// default_value is used when no value is supplied at execution time.
	DefaultValue string `json:"default_value,omitempty" jsonschema:"default_value is used when no value is supplied at execution time."`
	// description is a human-readable explanation of the variable's purpose.
	Description string `json:"description,omitempty" jsonschema:"description is a human-readable explanation of the variable's purpose."`
}

func (s *AwsCodePipelineVariableInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	return nil
}

func (s *AwsCodePipelineVariableInput) applyDefaults() {
}

func (s *AwsCodePipelineVariableInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	if s.DefaultValue != "" {
		m["default_value"] = s.DefaultValue
	}
	if s.Description != "" {
		m["description"] = s.Description
	}
	return m
}

// ParseAwsCodePipeline validates and normalizes a AwsCodePipeline cloud_object.
func ParseAwsCodePipeline(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "aws.openmcf.org/v1", "AwsCodePipeline"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec AwsCodePipelineSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
