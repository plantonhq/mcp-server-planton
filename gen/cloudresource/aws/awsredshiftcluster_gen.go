// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-27T00:55:48+05:30

package aws

import (
	"encoding/json"
	"fmt"

	"github.com/plantonhq/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// aws-redshift-cluster
type AwsRedshiftClusterSpecInput struct {
	// The AWS region where the resource will be created.
	//  Example: "us-west-2", "eu-west-1"
	Region string `json:"region,omitempty" jsonschema:"The AWS region where the resource will be created. Example: 'us-west-2'; 'eu-west-1'"`
	// node_type determines the compute and storage capacity of each node.
	//  Common types: dc2.large (dense compute SSD), ra3.xlplus / ra3.4xlarge / ra3.16xlarge
	//  (managed storage with automatic data tiering between SSD and S3).
	//  RA3 nodes are recommended for most workloads due to decoupled compute and stor...
	NodeType string `json:"node_type" jsonschema:"required,node_type determines the compute and storage capacity of each node. Common types: dc2.large (dense compute SSD); ra3.xlplus / ra3.4xlarge / ra3.16xlarge (managed storage with automatic data tiering be..."`
	// number_of_nodes determines the cluster topology.
	//  1 = single-node (leader and compute combined); >1 = multi-node (separate leader + compute nodes).
	//  Multi-node clusters are required for production workloads.
	NumberOfNodes int32 `json:"number_of_nodes,omitempty" jsonschema:"number_of_nodes determines the cluster topology. 1 = single-node (leader and compute combined); >1 = multi-node (separate leader + compute nodes). Multi-node clusters are required for production workl..."`
	// database_name is the name of the first database created in the cluster.
	//  1-64 characters, lowercase alphanumeric and underscores only, must start with a letter or underscore.
	DatabaseName string `json:"database_name,omitempty" jsonschema:"database_name is the name of the first database created in the cluster. 1-64 characters; lowercase alphanumeric and underscores only; must start with a letter or underscore."`
	// master_username is the admin user for the cluster. Required for new clusters.
	//  1-128 characters, must start with a letter.
	MasterUsername string `json:"master_username,omitempty" jsonschema:"master_username is the admin user for the cluster. Required for new clusters. 1-128 characters; must start with a letter."`
	// master_password is the admin password (8-64 chars, at least one uppercase, one lowercase, one digit).
	//  Mutually exclusive with manage_master_password.
	MasterPassword string `json:"master_password,omitempty" jsonschema:"master_password is the admin password (8-64 chars; at least one uppercase; one lowercase; one digit). Mutually exclusive with manage_master_password."`
	// manage_master_password delegates password lifecycle to AWS Secrets Manager.
	//  When true, AWS generates, rotates, and stores the password automatically.
	//  Recommended for production. Mutually exclusive with master_password.
	ManageMasterPassword bool `json:"manage_master_password,omitempty" jsonschema:"manage_master_password delegates password lifecycle to AWS Secrets Manager. When true; AWS generates; rotates; and stores the password automatically. Recommended for production. Mutually exclusive wit..."`
	// master_password_secret_kms_key_id encrypts the Secrets Manager secret holding the managed password.
	//  Only applicable when manage_master_password is true.
	MasterPasswordSecretKmsKeyId string `json:"master_password_secret_kms_key_id,omitempty" jsonschema:"master_password_secret_kms_key_id encrypts the Secrets Manager secret holding the managed password. Only applicable when manage_master_password is true."`
	// port for client connections. Redshift default is 5439. Range: 1115-65535.
	Port int32 `json:"port,omitempty" jsonschema:"port for client connections. Redshift default is 5439. Range: 1115-65535."`
	// subnet_ids for automatic Redshift subnet group creation.
	//  Provide at least two subnets in distinct Availability Zones for high availability.
	SubnetIds []string `json:"subnet_ids,omitempty" jsonschema:"subnet_ids for automatic Redshift subnet group creation. Provide at least two subnets in distinct Availability Zones for high availability."`
	// cluster_subnet_group_name uses an existing Redshift subnet group instead of creating one from subnet_ids.
	ClusterSubnetGroupName string `json:"cluster_subnet_group_name,omitempty" jsonschema:"cluster_subnet_group_name uses an existing Redshift subnet group instead of creating one from subnet_ids."`
	// security_group_ids triggers creation of a managed security group with ingress rules
	//  allowing traffic from these source security groups on the cluster port.
	SecurityGroupIds []string `json:"security_group_ids,omitempty" jsonschema:"security_group_ids triggers creation of a managed security group with ingress rules allowing traffic from these source security groups on the cluster port."`
	// allowed_cidr_blocks triggers creation of a managed security group with ingress rules
	//  allowing traffic from these IPv4 CIDR ranges on the cluster port.
	AllowedCidrBlocks []string `json:"allowed_cidr_blocks,omitempty" jsonschema:"allowed_cidr_blocks triggers creation of a managed security group with ingress rules allowing traffic from these IPv4 CIDR ranges on the cluster port."`
	// associate_security_group_ids are existing security groups attached directly to the cluster
	//  (alongside the managed security group, if one is created from security_group_ids/allowed_cidr_blocks).
	AssociateSecurityGroupIds []string `json:"associate_security_group_ids,omitempty" jsonschema:"associate_security_group_ids are existing security groups attached directly to the cluster (alongside the managed security group; if one is created from security_group_ids/allowed_cidr_blocks)."`
	// vpc_id is required when security_group_ids or allowed_cidr_blocks are provided,
	//  as the managed security group must be created within a specific VPC.
	VpcId string `json:"vpc_id,omitempty" jsonschema:"vpc_id is required when security_group_ids or allowed_cidr_blocks are provided; as the managed security group must be created within a specific VPC."`
	// publicly_accessible controls whether the cluster has a public IP and can be accessed from outside the VPC.
	PubliclyAccessible bool `json:"publicly_accessible,omitempty" jsonschema:"publicly_accessible controls whether the cluster has a public IP and can be accessed from outside the VPC."`
	// enhanced_vpc_routing forces all COPY and UNLOAD traffic between the cluster and data repositories
	//  through the VPC, enabling VPC flow logs and other network security controls.
	EnhancedVpcRouting bool `json:"enhanced_vpc_routing,omitempty" jsonschema:"enhanced_vpc_routing forces all COPY and UNLOAD traffic between the cluster and data repositories through the VPC; enabling VPC flow logs and other network security controls."`
	// multi_az enables Multi-AZ deployment for automatic failover to a standby in a different AZ.
	//  Requires RA3 node types (ra3.xlplus, ra3.4xlarge, ra3.16xlarge).
	MultiAz bool `json:"multi_az,omitempty" jsonschema:"multi_az enables Multi-AZ deployment for automatic failover to a standby in a different AZ. Requires RA3 node types (ra3.xlplus; ra3.4xlarge; ra3.16xlarge)."`
	// encrypted enables at-rest encryption for the cluster data.
	//  AWS defaults to true. Uses the AWS-managed Redshift service key unless kms_key_id is specified.
	Encrypted bool `json:"encrypted,omitempty" jsonschema:"encrypted enables at-rest encryption for the cluster data. AWS defaults to true. Uses the AWS-managed Redshift service key unless kms_key_id is specified."`
	// kms_key_id is the ARN of a customer-managed KMS key for cluster encryption.
	//  Requires encrypted to be true. If omitted, AWS uses the default Redshift service key.
	KmsKeyId string `json:"kms_key_id,omitempty" jsonschema:"kms_key_id is the ARN of a customer-managed KMS key for cluster encryption. Requires encrypted to be true. If omitted; AWS uses the default Redshift service key."`
	// iam_roles attaches IAM roles to the cluster for accessing other AWS services
	//  (S3, DynamoDB, Glue Data Catalog, etc.) during COPY, UNLOAD, and Spectrum queries.
	//  Maximum 10 roles per cluster.
	IamRoles []string `json:"iam_roles,omitempty" jsonschema:"iam_roles attaches IAM roles to the cluster for accessing other AWS services (S3; DynamoDB; Glue Data Catalog; etc.) during COPY; UNLOAD; and Spectrum queries. Maximum 10 roles per cluster."`
	// default_iam_role_arn is the IAM role used by default when SQL commands access AWS services
	//  without explicitly specifying a role (e.g., unqualified COPY/UNLOAD).
	DefaultIamRoleArn string `json:"default_iam_role_arn,omitempty" jsonschema:"default_iam_role_arn is the IAM role used by default when SQL commands access AWS services without explicitly specifying a role (e.g.; unqualified COPY/UNLOAD)."`
	// automated_snapshot_retention_period is the number of days to retain automated cluster snapshots.
	//  0 disables automated snapshots. Maximum: 35.
	AutomatedSnapshotRetentionPeriod int32 `json:"automated_snapshot_retention_period,omitempty" jsonschema:"automated_snapshot_retention_period is the number of days to retain automated cluster snapshots. 0 disables automated snapshots. Maximum: 35."`
	// skip_final_snapshot controls whether a final manual snapshot is created before cluster deletion.
	//  Set to true only for ephemeral development/test clusters.
	SkipFinalSnapshot bool `json:"skip_final_snapshot,omitempty" jsonschema:"skip_final_snapshot controls whether a final manual snapshot is created before cluster deletion. Set to true only for ephemeral development/test clusters."`
	// final_snapshot_identifier is the name for the final snapshot created on deletion.
	//  Required when skip_final_snapshot is false.
	FinalSnapshotIdentifier string `json:"final_snapshot_identifier,omitempty" jsonschema:"final_snapshot_identifier is the name for the final snapshot created on deletion. Required when skip_final_snapshot is false."`
	// preferred_maintenance_window is the weekly UTC time range for system maintenance.
	//  Format: ddd:hh:mi-ddd:hh:mi (e.g., "sat:03:00-sat:04:00").
	PreferredMaintenanceWindow string `json:"preferred_maintenance_window,omitempty" jsonschema:"preferred_maintenance_window is the weekly UTC time range for system maintenance. Format: ddd:hh:mi-ddd:hh:mi (e.g.; 'sat:03:00-sat:04:00')."`
	// allow_version_upgrade permits AWS to automatically apply major engine version upgrades
	//  during the maintenance window.
	AllowVersionUpgrade bool `json:"allow_version_upgrade,omitempty" jsonschema:"allow_version_upgrade permits AWS to automatically apply major engine version upgrades during the maintenance window."`
	// maintenance_track_name determines the cluster maintenance version track.
	//  "current" applies the latest approved version; "trailing" uses the previous major version.
	MaintenanceTrackName string `json:"maintenance_track_name,omitempty" jsonschema:"maintenance_track_name determines the cluster maintenance version track. 'current' applies the latest approved version; 'trailing' uses the previous major version."`
	// apply_immediately controls whether modifications are applied immediately or deferred
	//  to the next maintenance window.
	ApplyImmediately bool `json:"apply_immediately,omitempty" jsonschema:"apply_immediately controls whether modifications are applied immediately or deferred to the next maintenance window."`
	// logging configures audit logging for the cluster.
	//  Redshift can send connection, user activity, and user logs to S3 or CloudWatch Logs.
	Logging *AwsRedshiftClusterLoggingInput `json:"logging,omitempty" jsonschema:"logging configures audit logging for the cluster. Redshift can send connection; user activity; and user logs to S3 or CloudWatch Logs."`
	// cluster_parameter_group_name associates an existing Redshift parameter group with the cluster.
	//  Ignored when inline parameters are provided (a new group is created instead).
	ClusterParameterGroupName string `json:"cluster_parameter_group_name,omitempty" jsonschema:"cluster_parameter_group_name associates an existing Redshift parameter group with the cluster. Ignored when inline parameters are provided (a new group is created instead)."`
	// parameters creates an inline parameter group (family: redshift-1.0) with these parameters.
	//  Common parameters: require_ssl, enable_user_activity_logging, max_concurrency_scaling_clusters.
	Parameters []*AwsRedshiftClusterParameterInput `json:"parameters,omitempty" jsonschema:"parameters creates an inline parameter group (family: redshift-1.0) with these parameters. Common parameters: require_ssl; enable_user_activity_logging; max_concurrency_scaling_clusters."`
}

func (s *AwsRedshiftClusterSpecInput) validate() error {
	if s.NodeType == "" {
		return fmt.Errorf("node_type is required")
	}
	if s.Logging != nil {
		if err := s.Logging.validate(); err != nil {
			return fmt.Errorf("logging: %w", err)
		}
	}
	for i, v := range s.Parameters {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("parameters[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *AwsRedshiftClusterSpecInput) applyDefaults() {
	if s.NumberOfNodes == 0 {
		s.NumberOfNodes = 1
	}
	if s.DatabaseName == "" {
		s.DatabaseName = "dev"
	}
	if s.MasterUsername == "" {
		s.MasterUsername = "admin"
	}
	if s.Port == 0 {
		s.Port = 5439
	}
	// default: Encrypted = true (applied at zero-value)
	if s.AutomatedSnapshotRetentionPeriod == 0 {
		s.AutomatedSnapshotRetentionPeriod = 1
	}
	// default: AllowVersionUpgrade = true (applied at zero-value)
	if s.Logging != nil {
		s.Logging.applyDefaults()
	}
}

func (s *AwsRedshiftClusterSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Region != "" {
		m["region"] = s.Region
	}
	m["node_type"] = s.NodeType
	if s.NumberOfNodes != 0 {
		m["number_of_nodes"] = s.NumberOfNodes
	}
	if s.DatabaseName != "" {
		m["database_name"] = s.DatabaseName
	}
	if s.MasterUsername != "" {
		m["master_username"] = s.MasterUsername
	}
	if s.MasterPassword != "" {
		m["master_password"] = s.MasterPassword
	}
	if s.ManageMasterPassword {
		m["manage_master_password"] = s.ManageMasterPassword
	}
	if s.MasterPasswordSecretKmsKeyId != "" {
		m["master_password_secret_kms_key_id"] = s.MasterPasswordSecretKmsKeyId
	}
	if s.Port != 0 {
		m["port"] = s.Port
	}
	if len(s.SubnetIds) > 0 {
		m["subnet_ids"] = s.SubnetIds
	}
	if s.ClusterSubnetGroupName != "" {
		m["cluster_subnet_group_name"] = s.ClusterSubnetGroupName
	}
	if len(s.SecurityGroupIds) > 0 {
		m["security_group_ids"] = s.SecurityGroupIds
	}
	if len(s.AllowedCidrBlocks) > 0 {
		m["allowed_cidr_blocks"] = s.AllowedCidrBlocks
	}
	if len(s.AssociateSecurityGroupIds) > 0 {
		m["associate_security_group_ids"] = s.AssociateSecurityGroupIds
	}
	if s.VpcId != "" {
		m["vpc_id"] = s.VpcId
	}
	if s.PubliclyAccessible {
		m["publicly_accessible"] = s.PubliclyAccessible
	}
	if s.EnhancedVpcRouting {
		m["enhanced_vpc_routing"] = s.EnhancedVpcRouting
	}
	if s.MultiAz {
		m["multi_az"] = s.MultiAz
	}
	if s.Encrypted {
		m["encrypted"] = s.Encrypted
	}
	if s.KmsKeyId != "" {
		m["kms_key_id"] = s.KmsKeyId
	}
	if len(s.IamRoles) > 0 {
		m["iam_roles"] = s.IamRoles
	}
	if s.DefaultIamRoleArn != "" {
		m["default_iam_role_arn"] = s.DefaultIamRoleArn
	}
	if s.AutomatedSnapshotRetentionPeriod != 0 {
		m["automated_snapshot_retention_period"] = s.AutomatedSnapshotRetentionPeriod
	}
	if s.SkipFinalSnapshot {
		m["skip_final_snapshot"] = s.SkipFinalSnapshot
	}
	if s.FinalSnapshotIdentifier != "" {
		m["final_snapshot_identifier"] = s.FinalSnapshotIdentifier
	}
	if s.PreferredMaintenanceWindow != "" {
		m["preferred_maintenance_window"] = s.PreferredMaintenanceWindow
	}
	if s.AllowVersionUpgrade {
		m["allow_version_upgrade"] = s.AllowVersionUpgrade
	}
	if s.MaintenanceTrackName != "" {
		m["maintenance_track_name"] = s.MaintenanceTrackName
	}
	if s.ApplyImmediately {
		m["apply_immediately"] = s.ApplyImmediately
	}
	if s.Logging != nil {
		m["logging"] = s.Logging.toMap()
	}
	if s.ClusterParameterGroupName != "" {
		m["cluster_parameter_group_name"] = s.ClusterParameterGroupName
	}
	if len(s.Parameters) > 0 {
		items := make([]any, len(s.Parameters))
		for i, v := range s.Parameters {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["parameters"] = items
	}
	return m
}

// AwsRedshiftClusterLogging configures audit logging for the Redshift cluster.
//
//	Redshift supports two log destinations: S3 buckets (traditional) and CloudWatch Logs (modern).
type AwsRedshiftClusterLoggingInput struct {
	// log_destination_type specifies where audit logs are delivered.
	//  "s3" writes logs to an S3 bucket; "cloudwatch" streams logs to CloudWatch Logs.
	LogDestinationType string `json:"log_destination_type" jsonschema:"required,log_destination_type specifies where audit logs are delivered. 's3' writes logs to an S3 bucket; 'cloudwatch' streams logs to CloudWatch Logs."`
	// s3_bucket_name is the S3 bucket for audit log delivery. Required when log_destination_type is "s3".
	S3BucketName string `json:"s3_bucket_name,omitempty" jsonschema:"s3_bucket_name is the S3 bucket for audit log delivery. Required when log_destination_type is 's3'."`
	// s3_key_prefix is an optional prefix for log objects within the S3 bucket.
	S3KeyPrefix string `json:"s3_key_prefix,omitempty" jsonschema:"s3_key_prefix is an optional prefix for log objects within the S3 bucket."`
	// log_exports specifies which audit log types to export.
	//  Valid values: "connectionlog" (connection attempts), "useractivitylog" (SQL queries),
	//  "userlog" (user DDL changes). Required when log_destination_type is "cloudwatch".
	LogExports []string `json:"log_exports,omitempty" jsonschema:"log_exports specifies which audit log types to export. Valid values: 'connectionlog' (connection attempts); 'useractivitylog' (SQL queries); 'userlog' (user DDL changes). Required when log_destination..."`
}

func (s *AwsRedshiftClusterLoggingInput) validate() error {
	if s.LogDestinationType == "" {
		return fmt.Errorf("log_destination_type is required")
	}
	return nil
}

func (s *AwsRedshiftClusterLoggingInput) applyDefaults() {
}

func (s *AwsRedshiftClusterLoggingInput) toMap() map[string]any {
	m := make(map[string]any)
	m["log_destination_type"] = s.LogDestinationType
	if s.S3BucketName != "" {
		m["s3_bucket_name"] = s.S3BucketName
	}
	if s.S3KeyPrefix != "" {
		m["s3_key_prefix"] = s.S3KeyPrefix
	}
	if len(s.LogExports) > 0 {
		m["log_exports"] = s.LogExports
	}
	return m
}

// AwsRedshiftClusterParameter represents a key-value pair for a Redshift parameter group.
//
//	The parameter group family is always "redshift-1.0".
type AwsRedshiftClusterParameterInput struct {
	// name of the parameter (e.g., "require_ssl", "enable_user_activity_logging",
	//  "max_concurrency_scaling_clusters", "wlm_json_configuration").
	Name string `json:"name" jsonschema:"required,name of the parameter (e.g.; 'require_ssl'; 'enable_user_activity_logging'; 'max_concurrency_scaling_clusters'; 'wlm_json_configuration')."`
	// value of the parameter.
	Value string `json:"value" jsonschema:"required,value of the parameter."`
}

func (s *AwsRedshiftClusterParameterInput) validate() error {
	if s.Name == "" {
		return fmt.Errorf("name is required")
	}
	if s.Value == "" {
		return fmt.Errorf("value is required")
	}
	return nil
}

func (s *AwsRedshiftClusterParameterInput) applyDefaults() {
}

func (s *AwsRedshiftClusterParameterInput) toMap() map[string]any {
	m := make(map[string]any)
	m["name"] = s.Name
	m["value"] = s.Value
	return m
}

// ParseAwsRedshiftCluster validates and normalizes a AwsRedshiftCluster cloud_object.
func ParseAwsRedshiftCluster(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "aws.openmcf.org/v1", "AwsRedshiftCluster"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec AwsRedshiftClusterSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
