// Code generated by schema2go. DO NOT EDIT.
// Generated: 2026-02-27T00:55:48+05:30

package aws

import (
	"encoding/json"
	"fmt"

	"github.com/plantonhq/mcp-server-planton/internal/parse"
	"google.golang.org/protobuf/types/known/structpb"
)

var (
	_ = json.Marshal
	_ = fmt.Errorf
	_ = parse.ValidateHeader
	_ = (*structpb.Struct)(nil)
)

// aws-s3-bucket
type AwsS3BucketSpecInput struct {
	// The AWS region where the resource will be created.
	//  Example: "us-west-2", "eu-west-1"
	Region string `json:"region,omitempty" jsonschema:"The AWS region where the resource will be created. Example: 'us-west-2'; 'eu-west-1'"`
	// Flag to indicate if the S3 bucket should have external (public) access.
	//  When set to `true`, the bucket will be publicly accessible over the internet.
	//  When set to `false` (default), Block Public Access is enabled (recommended for security).
	//  Public access should be used cautiously to avoid unintend...
	IsPublic bool `json:"is_public,omitempty" jsonschema:"Flag to indicate if the S3 bucket should have external (public) access. When set to 'true'; the bucket will be publicly accessible over the internet. When set to 'false' (default); Block Public Access..."`
	// Enable versioning to protect against accidental deletions and overwrites.
	//  When enabled, S3 keeps all versions of an object. Recommended for production buckets.
	//  Note: Versioning increases storage costs as each version is stored separately.
	//  Use lifecycle policies to expire old versions and control ...
	VersioningEnabled bool `json:"versioning_enabled,omitempty" jsonschema:"Enable versioning to protect against accidental deletions and overwrites. When enabled; S3 keeps all versions of an object. Recommended for production buckets. Note: Versioning increases storage costs..."`
	// Encryption type for objects in the bucket.
	//  Defaults to SSE_S3 (AES-256) if unspecified, which is free and provides strong encryption.
	//  Use SSE_KMS for audit trails (CloudTrail logs key usage) and customer-managed key control.
	EncryptionType string `json:"encryption_type,omitempty" jsonschema:"enum=ENCRYPTION_TYPE_SSE_S3|ENCRYPTION_TYPE_SSE_KMS,Encryption type for objects in the bucket. Defaults to SSE_S3 (AES-256) if unspecified; which is free and provides strong encryption. Use SSE_KMS for audit trails (CloudTrail logs key usage) and custo..."`
	// KMS key ID or ARN for SSE-KMS encryption.
	//  Required when encryption_type is ENCRYPTION_TYPE_SSE_KMS.
	//  Leave empty for ENCRYPTION_TYPE_SSE_S3.
	//  Can reference an AwsKmsKey resource.
	KmsKeyId string `json:"kms_key_id,omitempty" jsonschema:"KMS key ID or ARN for SSE-KMS encryption. Required when encryption_type is ENCRYPTION_TYPE_SSE_KMS. Leave empty for ENCRYPTION_TYPE_SSE_S3. Can reference an AwsKmsKey resource."`
	// Tags for resource governance, cost allocation, and organization.
	//  Common tags: Environment (prod/staging), Project, Owner, CostCenter.
	//  AWS allows up to 50 tags per bucket.
	Tags map[string]string `json:"tags,omitempty" jsonschema:"Tags for resource governance; cost allocation; and organization. Common tags: Environment (prod/staging); Project; Owner; CostCenter. AWS allows up to 50 tags per bucket."`
	// Lifecycle rules for automatic storage transitions and expiration.
	//  Use lifecycle rules to:
	//  - Move old objects to cheaper storage (Standard -> IA -> Glacier)
	//  - Expire old logs or temporary data
	//  - Delete old object versions to control costs
	//  - Abort incomplete multipart uploads
	LifecycleRules []*LifecycleRuleInput `json:"lifecycle_rules,omitempty" jsonschema:"Lifecycle rules for automatic storage transitions and expiration. Use lifecycle rules to: - Move old objects to cheaper storage (Standard -> IA -> Glacier) - Expire old logs or temporary data - Delete..."`
	// Replication configuration for disaster recovery or compliance.
	//  Cross-Region Replication (CRR): replicate to different region for disaster recovery.
	//  Same-Region Replication (SRR): replicate to same region for cross-account backups or log aggregation.
	//  Note: Requires versioning_enabled = true on bot...
	Replication *ReplicationConfigurationInput `json:"replication,omitempty" jsonschema:"Replication configuration for disaster recovery or compliance. Cross-Region Replication (CRR): replicate to different region for disaster recovery. Same-Region Replication (SRR): replicate to same reg..."`
	// Server access logging configuration.
	//  Logs all requests made to the bucket for security audits and analytics.
	//  Access logs are delivered to a separate bucket with some delay (minutes to hours).
	//  Alternative: Use CloudTrail Data Events for real-time logging (higher cost for high-traffic buckets).
	Logging *LoggingConfigurationInput `json:"logging,omitempty" jsonschema:"Server access logging configuration. Logs all requests made to the bucket for security audits and analytics. Access logs are delivered to a separate bucket with some delay (minutes to hours). Alternat..."`
	// CORS configuration for web applications.
	//  Required when your web application hosted on one domain needs to access bucket content.
	//  Example: React app on example.com accessing S3 bucket for images/files.
	Cors *CorsConfigurationInput `json:"cors,omitempty" jsonschema:"CORS configuration for web applications. Required when your web application hosted on one domain needs to access bucket content. Example: React app on example.com accessing S3 bucket for images/files."`
	// Force destroy the bucket even if it contains objects.
	//  When true, all objects (including versions) are deleted before destroying the bucket.
	//  WARNING: Use with caution! This is irreversible.
	//  Recommended: false for production buckets to prevent accidental data loss.
	ForceDestroy bool `json:"force_destroy,omitempty" jsonschema:"Force destroy the bucket even if it contains objects. When true; all objects (including versions) are deleted before destroying the bucket. WARNING: Use with caution! This is irreversible. Recommended..."`
}

func (s *AwsS3BucketSpecInput) validate() error {
	switch s.EncryptionType {
	case "", "ENCRYPTION_TYPE_SSE_S3", "ENCRYPTION_TYPE_SSE_KMS":
	default:
		return fmt.Errorf("invalid encryption_type: %q", s.EncryptionType)
	}
	for i, v := range s.LifecycleRules {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("lifecycle_rules[%d]: %w", i, err)
			}
		}
	}
	if s.Replication != nil {
		if err := s.Replication.validate(); err != nil {
			return fmt.Errorf("replication: %w", err)
		}
	}
	if s.Logging != nil {
		if err := s.Logging.validate(); err != nil {
			return fmt.Errorf("logging: %w", err)
		}
	}
	if s.Cors != nil {
		if err := s.Cors.validate(); err != nil {
			return fmt.Errorf("cors: %w", err)
		}
	}
	return nil
}

func (s *AwsS3BucketSpecInput) applyDefaults() {
	if s.Replication != nil {
		s.Replication.applyDefaults()
	}
	if s.Logging != nil {
		s.Logging.applyDefaults()
	}
	if s.Cors != nil {
		s.Cors.applyDefaults()
	}
}

func (s *AwsS3BucketSpecInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Region != "" {
		m["region"] = s.Region
	}
	if s.IsPublic {
		m["is_public"] = s.IsPublic
	}
	if s.VersioningEnabled {
		m["versioning_enabled"] = s.VersioningEnabled
	}
	if s.EncryptionType != "" {
		m["encryption_type"] = s.EncryptionType
	}
	if s.KmsKeyId != "" {
		m["kms_key_id"] = s.KmsKeyId
	}
	if len(s.Tags) > 0 {
		m["tags"] = s.Tags
	}
	if len(s.LifecycleRules) > 0 {
		items := make([]any, len(s.LifecycleRules))
		for i, v := range s.LifecycleRules {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["lifecycle_rules"] = items
	}
	if s.Replication != nil {
		m["replication"] = s.Replication.toMap()
	}
	if s.Logging != nil {
		m["logging"] = s.Logging.toMap()
	}
	if s.Cors != nil {
		m["cors"] = s.Cors.toMap()
	}
	if s.ForceDestroy {
		m["force_destroy"] = s.ForceDestroy
	}
	return m
}

// CORS (Cross-Origin Resource Sharing) configuration.
type CorsConfigurationInput struct {
	// List of CORS rules.
	CorsRules []*CorsRuleInput `json:"cors_rules,omitempty" jsonschema:"List of CORS rules."`
}

func (s *CorsConfigurationInput) validate() error {
	for i, v := range s.CorsRules {
		if v != nil {
			if err := v.validate(); err != nil {
				return fmt.Errorf("cors_rules[%d]: %w", i, err)
			}
		}
	}
	return nil
}

func (s *CorsConfigurationInput) applyDefaults() {
}

func (s *CorsConfigurationInput) toMap() map[string]any {
	m := make(map[string]any)
	if len(s.CorsRules) > 0 {
		items := make([]any, len(s.CorsRules))
		for i, v := range s.CorsRules {
			if v != nil {
				items[i] = v.toMap()
			}
		}
		m["cors_rules"] = items
	}
	return m
}

// CORS rule.
type CorsRuleInput struct {
	// HTTP methods allowed (e.g., ["GET", "PUT", "POST"]).
	AllowedMethods []string `json:"allowed_methods,omitempty" jsonschema:"HTTP methods allowed (e.g.; ['GET'; 'PUT'; 'POST'])."`
	// Origins allowed (e.g., ["https://example.com"]).
	AllowedOrigins []string `json:"allowed_origins,omitempty" jsonschema:"Origins allowed (e.g.; ['https://example.com'])."`
	// Headers allowed in preflight requests.
	AllowedHeaders []string `json:"allowed_headers,omitempty" jsonschema:"Headers allowed in preflight requests."`
	// Headers exposed to the browser.
	ExposeHeaders []string `json:"expose_headers,omitempty" jsonschema:"Headers exposed to the browser."`
	// Time in seconds browser should cache preflight response.
	MaxAgeSeconds int32 `json:"max_age_seconds,omitempty" jsonschema:"Time in seconds browser should cache preflight response."`
}

func (s *CorsRuleInput) validate() error {
	if len(s.AllowedMethods) < 1 {
		return fmt.Errorf("allowed_methods requires at least 1 items, got %d", len(s.AllowedMethods))
	}
	if len(s.AllowedOrigins) < 1 {
		return fmt.Errorf("allowed_origins requires at least 1 items, got %d", len(s.AllowedOrigins))
	}
	return nil
}

func (s *CorsRuleInput) applyDefaults() {
}

func (s *CorsRuleInput) toMap() map[string]any {
	m := make(map[string]any)
	if len(s.AllowedMethods) > 0 {
		m["allowed_methods"] = s.AllowedMethods
	}
	if len(s.AllowedOrigins) > 0 {
		m["allowed_origins"] = s.AllowedOrigins
	}
	if len(s.AllowedHeaders) > 0 {
		m["allowed_headers"] = s.AllowedHeaders
	}
	if len(s.ExposeHeaders) > 0 {
		m["expose_headers"] = s.ExposeHeaders
	}
	if s.MaxAgeSeconds != 0 {
		m["max_age_seconds"] = s.MaxAgeSeconds
	}
	return m
}

// Destination bucket for replication.
type DestinationInput struct {
	// ARN of the destination bucket (e.g., "arn:aws:s3:::destination-bucket").
	BucketArn string `json:"bucket_arn,omitempty" jsonschema:"ARN of the destination bucket (e.g.; 'arn:aws:s3:::destination-bucket')."`
	// Destination storage class. If not specified, uses source object's storage class.
	StorageClass string `json:"storage_class,omitempty" jsonschema:"enum=STORAGE_CLASS_STANDARD|STORAGE_CLASS_STANDARD_IA|STORAGE_CLASS_ONE_ZONE_IA|STORAGE_CLASS_INTELLIGENT_TIERING|STORAGE_CLASS_GLACIER_INSTANT_RETRIEVAL|STORAGE_CLASS_GLACIER_FLEXIBLE_RETRIEVAL|STORAGE_CLASS_GLACIER_DEEP_ARCHIVE,Destination storage class. If not specified; uses source object's storage class."`
	// AWS account ID for cross-account replication. Leave empty for same-account.
	AccountId string `json:"account_id,omitempty" jsonschema:"AWS account ID for cross-account replication. Leave empty for same-account."`
}

func (s *DestinationInput) validate() error {
	switch s.StorageClass {
	case "", "STORAGE_CLASS_STANDARD", "STORAGE_CLASS_STANDARD_IA", "STORAGE_CLASS_ONE_ZONE_IA", "STORAGE_CLASS_INTELLIGENT_TIERING", "STORAGE_CLASS_GLACIER_INSTANT_RETRIEVAL", "STORAGE_CLASS_GLACIER_FLEXIBLE_RETRIEVAL", "STORAGE_CLASS_GLACIER_DEEP_ARCHIVE":
	default:
		return fmt.Errorf("invalid storage_class: %q", s.StorageClass)
	}
	return nil
}

func (s *DestinationInput) applyDefaults() {
}

func (s *DestinationInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.BucketArn != "" {
		m["bucket_arn"] = s.BucketArn
	}
	if s.StorageClass != "" {
		m["storage_class"] = s.StorageClass
	}
	if s.AccountId != "" {
		m["account_id"] = s.AccountId
	}
	return m
}

// Lifecycle rule to automate storage transitions and expiration.
type LifecycleRuleInput struct {
	// Unique identifier for the rule.
	Id string `json:"id,omitempty" jsonschema:"Unique identifier for the rule."`
	// Whether the rule is enabled.
	Enabled bool `json:"enabled,omitempty" jsonschema:"Whether the rule is enabled."`
	// Prefix filter for objects affected by this rule (e.g., "logs/").
	//  Empty string applies to all objects in the bucket.
	Prefix string `json:"prefix,omitempty" jsonschema:"Prefix filter for objects affected by this rule (e.g.; 'logs/'). Empty string applies to all objects in the bucket."`
	// Days after creation to transition objects to the specified storage class.
	TransitionDays int32 `json:"transition_days,omitempty" jsonschema:"Days after creation to transition objects to the specified storage class."`
	// Target storage class for transition.
	TransitionStorageClass string `json:"transition_storage_class,omitempty" jsonschema:"enum=STORAGE_CLASS_STANDARD|STORAGE_CLASS_STANDARD_IA|STORAGE_CLASS_ONE_ZONE_IA|STORAGE_CLASS_INTELLIGENT_TIERING|STORAGE_CLASS_GLACIER_INSTANT_RETRIEVAL|STORAGE_CLASS_GLACIER_FLEXIBLE_RETRIEVAL|STORAGE_CLASS_GLACIER_DEEP_ARCHIVE,Target storage class for transition."`
	// Days after creation to expire (delete) objects. 0 means no expiration.
	ExpirationDays int32 `json:"expiration_days,omitempty" jsonschema:"Days after creation to expire (delete) objects. 0 means no expiration."`
	// Days after becoming noncurrent to expire old versions. Only applies if versioning is enabled.
	NoncurrentVersionExpirationDays int32 `json:"noncurrent_version_expiration_days,omitempty" jsonschema:"Days after becoming noncurrent to expire old versions. Only applies if versioning is enabled."`
	// Days to abort incomplete multipart uploads. Recommended: 7 days.
	AbortIncompleteMultipartUploadDays int32 `json:"abort_incomplete_multipart_upload_days,omitempty" jsonschema:"Days to abort incomplete multipart uploads. Recommended: 7 days."`
}

func (s *LifecycleRuleInput) validate() error {
	switch s.TransitionStorageClass {
	case "", "STORAGE_CLASS_STANDARD", "STORAGE_CLASS_STANDARD_IA", "STORAGE_CLASS_ONE_ZONE_IA", "STORAGE_CLASS_INTELLIGENT_TIERING", "STORAGE_CLASS_GLACIER_INSTANT_RETRIEVAL", "STORAGE_CLASS_GLACIER_FLEXIBLE_RETRIEVAL", "STORAGE_CLASS_GLACIER_DEEP_ARCHIVE":
	default:
		return fmt.Errorf("invalid transition_storage_class: %q", s.TransitionStorageClass)
	}
	return nil
}

func (s *LifecycleRuleInput) applyDefaults() {
}

func (s *LifecycleRuleInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Id != "" {
		m["id"] = s.Id
	}
	if s.Enabled {
		m["enabled"] = s.Enabled
	}
	if s.Prefix != "" {
		m["prefix"] = s.Prefix
	}
	if s.TransitionDays != 0 {
		m["transition_days"] = s.TransitionDays
	}
	if s.TransitionStorageClass != "" {
		m["transition_storage_class"] = s.TransitionStorageClass
	}
	if s.ExpirationDays != 0 {
		m["expiration_days"] = s.ExpirationDays
	}
	if s.NoncurrentVersionExpirationDays != 0 {
		m["noncurrent_version_expiration_days"] = s.NoncurrentVersionExpirationDays
	}
	if s.AbortIncompleteMultipartUploadDays != 0 {
		m["abort_incomplete_multipart_upload_days"] = s.AbortIncompleteMultipartUploadDays
	}
	return m
}

// Server access logging configuration.
type LoggingConfigurationInput struct {
	// Whether logging is enabled.
	Enabled bool `json:"enabled,omitempty" jsonschema:"Whether logging is enabled."`
	// Target bucket for access logs. Must be in the same region.
	TargetBucket string `json:"target_bucket,omitempty" jsonschema:"Target bucket for access logs. Must be in the same region."`
	// Prefix for log object keys (e.g., "logs/mybucket/").
	TargetPrefix string `json:"target_prefix,omitempty" jsonschema:"Prefix for log object keys (e.g.; 'logs/mybucket/')."`
}

func (s *LoggingConfigurationInput) validate() error {
	return nil
}

func (s *LoggingConfigurationInput) applyDefaults() {
}

func (s *LoggingConfigurationInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Enabled {
		m["enabled"] = s.Enabled
	}
	if s.TargetBucket != "" {
		m["target_bucket"] = s.TargetBucket
	}
	if s.TargetPrefix != "" {
		m["target_prefix"] = s.TargetPrefix
	}
	return m
}

// Cross-region or same-region replication configuration.
type ReplicationConfigurationInput struct {
	// Whether replication is enabled.
	Enabled bool `json:"enabled,omitempty" jsonschema:"Whether replication is enabled."`
	// ARN of the IAM role that S3 assumes to replicate objects.
	//  The role must have permissions to read from source bucket and write to destination.
	//  Can reference an AwsIamRole resource.
	RoleArn string `json:"role_arn" jsonschema:"required,ARN of the IAM role that S3 assumes to replicate objects. The role must have permissions to read from source bucket and write to destination. Can reference an AwsIamRole resource."`
	// Destination configuration.
	Destination *DestinationInput `json:"destination" jsonschema:"required,Destination configuration."`
	// Prefix filter for objects to replicate. Empty string replicates all objects.
	Prefix string `json:"prefix,omitempty" jsonschema:"Prefix filter for objects to replicate. Empty string replicates all objects."`
	// Priority for replication rules. Higher numbers have higher priority.
	Priority int32 `json:"priority,omitempty" jsonschema:"Priority for replication rules. Higher numbers have higher priority."`
}

func (s *ReplicationConfigurationInput) validate() error {
	if s.RoleArn == "" {
		return fmt.Errorf("role_arn is required")
	}
	if s.Destination == nil {
		return fmt.Errorf("destination is required")
	}
	if s.Destination != nil {
		if err := s.Destination.validate(); err != nil {
			return fmt.Errorf("destination: %w", err)
		}
	}
	return nil
}

func (s *ReplicationConfigurationInput) applyDefaults() {
	if s.Destination != nil {
		s.Destination.applyDefaults()
	}
}

func (s *ReplicationConfigurationInput) toMap() map[string]any {
	m := make(map[string]any)
	if s.Enabled {
		m["enabled"] = s.Enabled
	}
	m["role_arn"] = s.RoleArn
	if s.Destination != nil {
		m["destination"] = s.Destination.toMap()
	}
	if s.Prefix != "" {
		m["prefix"] = s.Prefix
	}
	if s.Priority != 0 {
		m["priority"] = s.Priority
	}
	return m
}

// ParseAwsS3Bucket validates and normalizes a AwsS3Bucket cloud_object.
func ParseAwsS3Bucket(cloudObject map[string]any) (*structpb.Struct, error) {
	if err := parse.ValidateHeader(cloudObject, "aws.openmcf.org/v1", "AwsS3Bucket"); err != nil {
		return nil, err
	}

	specMap, err := parse.ExtractSpecMap(cloudObject)
	if err != nil {
		return nil, err
	}

	specBytes, err := json.Marshal(specMap)
	if err != nil {
		return nil, fmt.Errorf("marshal spec: %w", err)
	}

	var spec AwsS3BucketSpecInput
	if err := json.Unmarshal(specBytes, &spec); err != nil {
		return nil, fmt.Errorf("invalid spec: %w", err)
	}

	if err := spec.validate(); err != nil {
		return nil, err
	}

	spec.applyDefaults()

	return parse.RebuildCloudObject(cloudObject, spec.toMap())
}
